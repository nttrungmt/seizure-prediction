{
 "metadata": {
  "name": "",
  "signature": "sha256:445f09304b0bdd18ad256f2f2d5ce03e3ac782d49bcae13acc05073193f76b49"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "with 140925-metainfo I found that the negative examples (interictal) also have sequences. I fixed the `gen_ictal` to generate inter-sequnece segments also for the negative examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read precomputed features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "uncommoent the relevant pipeline in `../seizure_detection.py` and run\n",
      "```bash\n",
      "cd ..\n",
      "./doall data\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_data(target, data_type):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,FEATURES),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.linear_model import LogisticRegression as LR\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=3000, min_samples_split=1, bootstrap=False,max_depth=5,\n",
      "                             n_jobs=-1) #"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with_weights = False\n",
      "PWEIGHT = 6.\n",
      "LWEIGHT = 0.\n",
      "suffix = 'max_depth5.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "split examples into segments, each from the same event\n",
      "in each CV-split we will take all examples from the same segment to either train or validate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(np.arange(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(np.arange(start,i+1))\n",
      "    return np.array(segments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata.latencies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([], dtype=float64)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute AUC for each target separatly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "target2iter2ys = {}\n",
      "for target in ['Dog_1', 'Dog_2', 'Dog_3', 'Dog_4', 'Dog_5', 'Patient_1', 'Patient_2']:\n",
      "    # positive examples\n",
      "    pdata = read_data(target, 'preictal')\n",
      "    Np, NF = pdata.X.shape\n",
      "    \n",
      "    psegments = getsegments(pdata)\n",
      "    Nps = len(psegments)\n",
      "\n",
      "    # negative examples\n",
      "    ndata = read_data(target, 'interictal')\n",
      "    Nn, NF = ndata.X.shape\n",
      "    nsegments = getsegments(ndata)\n",
      "    Nns = len(nsegments)\n",
      "    \n",
      "    npratio = float(Nn)/Np\n",
      "    print target,1/(1+npratio),Np,Nn\n",
      "    npsratio = float(Nns)/Nps\n",
      "    print target,1/(1+npsratio),Nps,Nns\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = int(Ntrainps*npsratio)\n",
      "\n",
      "    iter2ys = defaultdict(list) # {niter: Ns *[(ytest,y_proba)]\n",
      "    for s in psegments:\n",
      "        Xtestp = pdata.X[s,:]\n",
      "        weightstest = pdata.latencies[s] # latency for first segment is 1\n",
      "        \n",
      "        Ntrainp = len(s)\n",
      "        Ntrainn = int(Ntrainp*npratio)\n",
      "        \n",
      "        for niter in range(3):\n",
      "\n",
      "#             n = np.array(random.sample(xrange(Nn),Ntrainn)) # segment based\n",
      "            ns = np.array(random.sample(xrange(Nns),Ntrainns)) # sequence based\n",
      "            n = np.array(list(itertools.chain(*nsegments[ns]))) # .ravel does not work - elements of nsegments are not of equal length\n",
      "            Xtestn = ndata.X[n,:]\n",
      "\n",
      "            Xtrainp = pdata.X[-s,:]\n",
      "            Xtrainn = ndata.X[-n,:]\n",
      "\n",
      "            Xtrain = np.concatenate((Xtrainp,Xtrainn))\n",
      "            ytrain = np.concatenate((np.ones(Xtrainp.shape[0]),np.zeros(Xtrainn.shape[0])))\n",
      "            perm = np.random.permutation(len(ytrain))\n",
      "            ytrain = ytrain[perm]\n",
      "            Xtrain = Xtrain[perm,:]\n",
      "\n",
      "            Xtest = np.concatenate((Xtestp,Xtestn))\n",
      "            ytest = np.concatenate((np.ones(Xtestp.shape[0]),np.zeros(Xtestn.shape[0])))\n",
      "\n",
      "            if with_weights:\n",
      "                weightsp = PWEIGHT*np.ones(Xtrainp.shape[0])\n",
      "                weightsp += LWEIGHT * (pdata.latencies[-s]-1.) # latency for first segment is 1\n",
      "                weightsn = np.ones(Xtrainn.shape[0]) \n",
      "                weights = np.concatenate((weightsp,weightsn))\n",
      "                weights = weights[perm]\n",
      "                clf.fit(Xtrain, ytrain, sample_weight=weights)\n",
      "            else:\n",
      "                clf.fit(Xtrain, ytrain)\n",
      "\n",
      "            y_proba = clf.predict_proba(Xtest)[:,1]\n",
      "            iter2ys[niter].append((ytest, y_proba))\n",
      "            \n",
      "            auc = roc_auc_score(ytest, y_proba)\n",
      "            print '%.3f'%auc,Ntrainp,np.mean(weightstest)\n",
      "    target2iter2ys[target] = iter2ys\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'i' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-498293405690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'interictal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mNn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnsegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsegments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mNns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-8-9b641fb407a7>\u001b[0m in \u001b[0;36mgetsegments\u001b[0;34m(pdata)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlast_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msegments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = '../data-cache/140926-CV.%s%s.pkl'%(suffix, FEATURES)\n",
      "with open(fname,'wb') as fp:\n",
      "    pickle.dump(target2iter2ys,fp,-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "'../data-cache/140926-CV.max_depth5.p6.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9.pkl'"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a single AUC score"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def p(a,b):\n",
      "    return '%d E%d'%(1000*a,1000*b)\n",
      "\n",
      "for f in [\n",
      "            'max_depth5.p6.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "            'max_depth5.p8.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "            'max_depth5.p1.2.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "            'max_depth5.p1.1.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "            'max_depth5.p1.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "            'max_depth5.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9',\n",
      "        ]:\n",
      "    all_ytest = all_y_proba =None\n",
      "    all_aucs = []\n",
      "    with open('../data-cache/140926-CV.%s.pkl'%f,'rb') as fp:\n",
      "        target2iter2ys = pickle.load(fp)\n",
      "    for target, iter2ys in target2iter2ys.iteritems():\n",
      "        target_ytest = target_y_proba =None\n",
      "        target_aucs = []\n",
      "        print target,\n",
      "        for ys in iter2ys.itervalues():\n",
      "            ytest = y_proba =None\n",
      "            aucs = []\n",
      "            for y in ys:\n",
      "                yt, yp = y\n",
      "                ytest = yt if ytest is None else np.concatenate((ytest,yt))\n",
      "                y_proba = yp if y_proba is None else np.concatenate((y_proba,yp))\n",
      "                aucs.append(roc_auc_score(yt, yp))\n",
      "            print p(roc_auc_score(ytest, y_proba), np.mean(aucs)),\n",
      "            target_aucs += aucs\n",
      "            target_ytest = ytest if target_ytest is None else np.concatenate((target_ytest,ytest))\n",
      "            target_y_proba = y_proba if target_y_proba is None else np.concatenate((target_y_proba,y_proba))\n",
      "        print target,p(roc_auc_score(target_ytest, target_y_proba),np.mean(target_aucs))\n",
      "        all_aucs += target_aucs        \n",
      "        all_ytest = target_ytest if all_ytest is None else np.concatenate((all_ytest,target_ytest))\n",
      "        all_y_proba = target_y_proba if all_y_proba is None else np.concatenate((all_y_proba,target_y_proba))\n",
      "#         if target == 'Dog_3':\n",
      "#             pl.hist(target_aucs,alpha=0.5)\n",
      "    print f,p(roc_auc_score(all_ytest, all_y_proba),np.mean(all_aucs))\n",
      "    print\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_2 884 E917 900 E941 904 E930 Dog_2 894 E929\n",
        "Dog_3 798 E796 761 E769 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "768 E785 Dog_3 776 E783\n",
        "Dog_1 516 E517 606 E632 644 E669 Dog_1 589 E606\n",
        "Dog_4 599 E597 578 E593 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "576 E575 Dog_4 585 E588\n",
        "Dog_5 946 E949 914 E927 943 E956 Dog_5 933 E944\n",
        "Patient_2 883 E998 761 E737 781 E936 Patient_2 813 E890\n",
        "Patient_1 732 E701 760 E719 792 E844 Patient_1 762 E754\n",
        "max_depth5.p6.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "761 E745\n",
        "\n",
        "Dog_2 883 E920 900 E926 907 E939 Dog_2 897 E929\n",
        "Dog_3 813 E820 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "767 E746 776 E782 Dog_3 785 E783\n",
        "Dog_1 584 E593 485 E495 557 E542 Dog_1 542 E543\n",
        "Dog_4 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "557 E572 622 E624 617 E653 Dog_4 600 E616\n",
        "Dog_5 908 E907 959 E959 911 E894 Dog_5 925 E920\n",
        "Patient_2 998 E999 888 E997 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "858 E808 Patient_2 915 E934\n",
        "Patient_1 713 E737 785 E751 733 E726 Patient_1 746 E738\n",
        "max_depth5.p8.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 766 E748\n",
        "\n",
        "Dog_2 725 E779 850 E866 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "790 E921 Dog_2 792 E855\n",
        "Dog_3 685 E652 568 E536 643 E700 Dog_3 627 E629\n",
        "Dog_1 731 E706 427 E467 673 E765 Dog_1 609 E646\n",
        "Dog_4 507 E529 567 E576 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "541 E586 Dog_4 541 E563\n",
        "Dog_5 873 E861 844 E942 848 E837 Dog_5 850 E880\n",
        "Patient_2 863 E790 993 E1000 780 E998 Patient_2 873 E929\n",
        "Patient_1 768 E566 508 E477 716 E550 Patient_1 665 E531\n",
        "max_depth5.p1.2.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 665 E676\n",
        "\n",
        "Dog_2 906 E931 893 E937 881 E931 Dog_2 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "894 E933\n",
        "Dog_3 779 E760 772 E780 736 E733 Dog_3 763 E758\n",
        "Dog_1 632 E648 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "553 E556 607 E621 Dog_1 594 E608\n",
        "Dog_4 569 E611 606 E625 641 E686 Dog_4 607 E640\n",
        "Dog_5 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "897 E886 904 E886 937 E953 Dog_5 911 E908\n",
        "Patient_2 885 E938 844 E904 853 E796 Patient_2 875 E879\n",
        "Patient_1 644 E531 678 E635 709 E734 Patient_1 680 E633\n",
        "max_depth5.p1.1.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "769 E746\n",
        "\n",
        "Dog_2 869 E909 847 E880 915 E936 Dog_2 877 E908\n",
        "Dog_3 789 E800 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "718 E721 760 E744 Dog_3 756 E755\n",
        "Dog_1 611 E628 608 E608 624 E639 Dog_1 615 E625\n",
        "Dog_4 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "578 E597 640 E672 604 E624 Dog_4 606 E631\n",
        "Dog_5 858 E865 943 E958 910 E932 Dog_5 905 E918\n",
        "Patient_2 947 E996 777 E833 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "909 E1000 Patient_2 881 E943\n",
        "Patient_1 765 E811 743 E739 835 E820 Patient_1 778 E790\n",
        "max_depth5.p1.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 764 E753\n",
        "\n",
        "Dog_2 896 E935 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "884 E917 876 E919 Dog_2 884 E924\n",
        "Dog_3 724 E719 756 E773 777 E788 Dog_3 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "752 E760\n",
        "Dog_1 562 E579 642 E661 643 E652 Dog_1 618 E631\n",
        "Dog_4 643 E663 602 E637 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "605 E632 Dog_4 615 E644\n",
        "Dog_5 951 E950 913 E928 958 E961 Dog_5 940 E946\n",
        "Patient_2 702 E765 899 E978 821 E900 Patient_2 813 E881\n",
        "Patient_1 767 E752 757 E746 694 E592 Patient_1 745 E697\n",
        "max_depth5.gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "765 E755\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}