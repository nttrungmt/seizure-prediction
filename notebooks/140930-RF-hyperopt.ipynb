{
 "metadata": {
  "name": "",
  "signature": "sha256:15f8a1701b6646af19b7520f6f17485186e95d3e51456de5bfa8d562b04694f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 270
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LOCAL_HOSTNAME=!hostname\n",
      "if LOCAL_HOSTNAME[0].startswith('ip-'):\n",
      "    !aws s3 cp s3://udikaggle/sezure/{FEATURES}.tgz data-cache/\n",
      "    !tar xfz data-cache/{FEATURES}.tgz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 272
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 273,
       "text": [
        "(184, 240)"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "(480, 240)"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_1 0.277108433735 184 480\n",
        "Dog_1 0.047619047619 4 80\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 277,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 280,
       "text": [
        "(664, 240)"
       ]
      }
     ],
     "prompt_number": 280
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 281,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 282,
       "text": [
        "0.80271084337349397"
       ]
      }
     ],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 283,
       "text": [
        "[<matplotlib.lines.Line2D at 0x117b39510>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1159de950>"
       ]
      }
     ],
     "prompt_number": 283
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 284
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 286,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 286
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    if pratio == 0:\n",
      "        return range(N), []\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 289
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn.ensemble import RandomForestClassifier\n",
      "            est = RandomForestClassifier()\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 290
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'pratio': 1,\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'n_estimators': hp.qloguniform('learning_rate', np.log(50), np.log(4000), 1),\n",
      "    'criterion': hp.choice('criterion',['gini', 'entropy']),\n",
      "    'max_depth': hp.choice('max_depth',\n",
      "            [None, hp.qlognormal('max_depth_int', np.log(5), 1, 1)]),\n",
      "    'min_samples_split': hp.qloguniform('min_samples_split', np.log(1.), np.log(5.), 1),\n",
      "    'min_samples_leaf': hp.qloguniform('min_samples_leaf', np.log(1.), np.log(5.), 1),\n",
      "    'bootstrap': hp.choice('bootstrap',[False, True]),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 280.0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 3.0,\n",
        " 'nf': 10.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 3756.0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 2.0,\n",
        " 'nf': 10.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 1,\n",
        " 'learning_rate': 351.0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 2.0,\n",
        " 'min_samples_split': 4.0,\n",
        " 'nf': 119.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 77.0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 5.0,\n",
        " 'min_samples_split': 4.0,\n",
        " 'nf': 11.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 1,\n",
        " 'learning_rate': 766.0,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 5.0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 4.0,\n",
        " 'nf': 159.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:42]: \u001b[0m\n",
        "{'bootstrap': 0,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 50.0,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 15.0,\n",
        " 'min_samples_leaf': 5.0,\n",
        " 'min_samples_split': 3.0,\n",
        " 'nf': 10.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 657.0,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 69.0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 3.0,\n",
        " 'nf': 10.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:42]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'learning_rate': 60.0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 3.0,\n",
        " 'min_samples_split': 1.0,\n",
        " 'nf': 127.0}"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.984782608696 1.0 {'bootstrap': True, 'nf': 119.0, 'min_samples_leaf': 2.0, 'n_estimators': 351.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 4.0, 'max_depth': None}\r\n",
        "0.983605072464 1.0 {'bootstrap': True, 'nf': 160.0, 'min_samples_leaf': 1.0, 'n_estimators': 1278.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'max_depth': None}\r\n",
        "0.983152173913 1.0 {'bootstrap': True, 'nf': 169.0, 'min_samples_leaf': 1.0, 'n_estimators': 1706.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'max_depth': None}\r\n",
        "0.982065217391 1.0 {'bootstrap': True, 'nf': 170.0, 'min_samples_leaf': 1.0, 'n_estimators': 769.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'max_depth': None}\r\n",
        "0.981612318841 1.0 {'bootstrap': True, 'nf': 174.0, 'min_samples_leaf': 1.0, 'n_estimators': 1647.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'max_depth': None}\r\n"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    args = eval(''.join(l[2:]))\n",
      "    hyeropt_results.append((validate_score, train_score, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "798"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 296,
       "text": [
        "(502, 240)"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: /tmp/Xt.mmap: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=0)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    if sample_validate:\n",
      "        X_val = X[sample_validate,:NF]\n",
      "        y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    est = RandomForestClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        if sample_validate:\n",
      "            y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        else:\n",
      "            y_val_est = None\n",
      "\n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    if sample_validate:\n",
      "        return roc_auc_score(y_val, y_val_est)\n",
      "    else:\n",
      "        return 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for res in hyeropt_results:\n",
      "    args = res[2]\n",
      "    print args\n",
      "    args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'n_estimators': 351.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 4.0, 'bootstrap': True, 'max_depth': None, 'nf': 119.0, 'min_samples_leaf': 2.0}\n",
        "{'n_estimators': 1278.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 160.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1706.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 169.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 769.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 170.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1647.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 174.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1713.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 123.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 909.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 137.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1163.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 149.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 650.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': True, 'max_depth': None, 'nf': 90.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1736.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 177.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 1076.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 166.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 830.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 154.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 96.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 3.0, 'bootstrap': True, 'max_depth': None, 'nf': 161.0, 'min_samples_leaf': 4.0}\n",
        "{'n_estimators': 489.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 182.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 2462.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 143.0, 'min_samples_leaf': 1.0}\n",
        "{'n_estimators': 517.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 207.0, 'min_samples_leaf': 1.0}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 302,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{'n_estimators': 256.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 5.0, 'bootstrap': True, 'max_depth': None, 'nf': 68.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 480.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 5.0, 'bootstrap': True, 'max_depth': None, 'nf': 66.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 696.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 4.0, 'bootstrap': True, 'max_depth': None, 'nf': 62.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 50.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 5.0, 'bootstrap': True, 'max_depth': None, 'nf': 56.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 114.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 5.0, 'bootstrap': True, 'max_depth': None, 'nf': 55.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 198.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': True, 'max_depth': None, 'nf': 47.0, 'min_samples_leaf': 1.0}\n",
      "{'n_estimators': 157.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 4.0, 'bootstrap': True, 'max_depth': None, 'nf': 22.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 62.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': False, 'max_depth': None, 'nf': 90.0, 'min_samples_leaf': 1.0}\n",
      "{'n_estimators': 139.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': False, 'max_depth': None, 'nf': 87.0, 'min_samples_leaf': 1.0}\n",
      "{'n_estimators': 89.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 1.0, 'bootstrap': False, 'max_depth': 23.0, 'nf': 80.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 2201.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': False, 'max_depth': 9.0, 'nf': 60.0, 'min_samples_leaf': 2.0}\n",
      "{'n_estimators': 845.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 4.0, 'bootstrap': False, 'max_depth': None, 'nf': 55.0, 'min_samples_leaf': 1.0}\n",
      "{'n_estimators': 3016.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'bootstrap': False, 'max_depth': None, 'nf': 49.0, 'min_samples_leaf': 4.0}\n",
      "{'n_estimators': 3100.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': False, 'max_depth': None, 'nf': 48.0, 'min_samples_leaf': 1.0}\n",
      "{'n_estimators': 583.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'bootstrap': False, 'max_depth': None, 'nf': 47.0, 'min_samples_leaf': 3.0}\n",
      "{'n_estimators': 148.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'bootstrap': False, 'max_depth': None, 'nf': 44.0, 'min_samples_leaf': 1.0}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 303,
       "text": [
        "{'bootstrap': False,\n",
        " 'criterion': 'gini',\n",
        " 'max_depth': None,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 2.0,\n",
        " 'n_estimators': 148.0,\n",
        " 'nf': 44.0,\n",
        " 'pratio': 1}"
       ]
      }
     ],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    if not sample_validate:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "if np.any(np.isnan(y_est)):\n",
      "    print np.sum(y_count == 0),len(y_count)\n",
      "else:\n",
      "    y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "    y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "    roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "664 664\n"
       ]
      }
     ],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 308
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140929-target-combine"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}