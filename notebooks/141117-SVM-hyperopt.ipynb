{
 "metadata": {
  "name": "",
  "signature": "sha256:0c2573593ba6804ba57366e72a0007a22bd5b42fc6483142002fd08efa4ae650"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70'\n",
      "FEATURES1 = 'gen-8_maxdiff-60'\n",
      "\n",
      "nbands = 0\n",
      "nwindows = 0\n",
      "for p in FEATURES.split('-'):\n",
      "    if p[0] == 'b':\n",
      "        nbands += 1\n",
      "    elif p[0] == 'w':\n",
      "        nwindows = int(p[1:])\n",
      "\n",
      "nbands -= 1\n",
      "nbands, nwindows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "(5, 60)"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "\n",
      "def read_data(target, data_type, features=FEATURES):\n",
      "    fname = 'data_%s_%s_%s'%(data_type,target,features)\n",
      "    print fname\n",
      "    return cached_data_loader.load(fname,None)\n",
      "\n",
      "def process(X, X1, percentile=[0.05,0.95], nunits=2, mask_level=5000):\n",
      "    N, Nf = X.shape\n",
      "    print '# samples',N,'# power points', Nf\n",
      "    nchannels = Nf / (nbands*nwindows)\n",
      "    print '# channels', nchannels\n",
      "\n",
      "    fix = defaultdict(int)\n",
      "    newX = []\n",
      "    for i in range(N):\n",
      "        nw = nwindows//nunits\n",
      "        windows = X[i,:].reshape((nunits,nw,-1))\n",
      "        mask = X1[i,:].reshape((nunits,nw,-1)) # max value for each channel\n",
      "        for j in range(nunits):\n",
      "            for k in range(nchannels):\n",
      "                m = mask[j,:,k] > mask_level # find large windows\n",
      "                if np.any(m):\n",
      "#                     print 'FIX', sum(m)\n",
      "                    fix[sum(m)] += 1\n",
      "                    if not np.all(m): # make sure we had at least one good window so we can re use its values\n",
      "                        # replace the bands of a large windows with the mean of the bands in all other windows\n",
      "                        windows[j,m,k*nbands:(k+1)*nbands] = np.mean(windows[j,~m,k*nbands:(k+1)*nbands], axis=0)\n",
      "        sorted_windows = np.sort(windows, axis=1)\n",
      "        features = np.concatenate([sorted_windows[:,int(p*nw),:] for p in percentile], axis=-1)\n",
      "        newX.append(features.ravel())\n",
      "    newX = np.array(newX)\n",
      "    print sorted(fix.items())\n",
      "    return newX\n",
      "\n",
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments\n",
      "\n",
      "def getdata():\n",
      "    pdata = read_data(target, 'preictal') # positive examples\n",
      "    Np, _ = pdata.X.shape\n",
      "    print 'Positive examples',Np,\n",
      "    psegments = getsegments(pdata)\n",
      "    Nps = len(psegments)\n",
      "    print 'sequences:',Nps\n",
      "    \n",
      "\n",
      "    ndata = read_data(target, 'interictal') # negative examples\n",
      "    Nn, _ = ndata.X.shape\n",
      "    print 'Negative',Nn,\n",
      "    nsegments = getsegments(ndata)\n",
      "    Nns = len(nsegments)\n",
      "    print 'sequences:',Nns\n",
      "\n",
      "    X = np.concatenate((pdata.X, ndata.X))\n",
      "    print 'p-ratio',float(Np)/(Np+Nn), 'sequences p-ratio:',float(Nps)/(Nps+Nns)\n",
      "    nsegments = [[s+Np for s in ns] for ns in nsegments]\n",
      "    latencies = np.concatenate((pdata.latencies,ndata.latencies))\n",
      "\n",
      "    pdata1 = read_data(target, 'preictal', FEATURES1) # positive examples\n",
      "    ndata1 = read_data(target, 'interictal', FEATURES1) # negative examples\n",
      "    X1 = np.concatenate((pdata1.X, ndata1.X))\n",
      "\n",
      "    print 'Training:'\n",
      "    X = process(X, X1)\n",
      "    \n",
      "    \n",
      "    y = np.zeros(X.shape[0])\n",
      "    y[:Np] = 1\n",
      "    \n",
      "    print 'Test:'\n",
      "    tdata = read_data(target, 'test') # test examples\n",
      "    tdata1 = read_data(target, 'test', FEATURES1) # test examples\n",
      "    Xt = process(tdata.X, tdata1.X)\n",
      "    \n",
      "    return X,y,Xt,psegments,nsegments,latencies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y,Xt,psegments,nsegments,latencies = getdata()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_preictal_Dog_1_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "Positive examples 184 sequences: 4\n",
        "data_interictal_Dog_1_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "Negative"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 480 sequences: 80\n",
        "p-ratio 0.277108433735 sequences p-ratio: 0.047619047619\n",
        "data_preictal_Dog_1_gen-8_maxdiff-60\n",
        "data_interictal_Dog_1_gen-8_maxdiff-60\n",
        "Training:\n",
        "# samples 664 # power points 4800\n",
        "# channels 16\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test:\n",
        "data_test_Dog_1_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "data_test_Dog_1_gen-8_maxdiff-60\n",
        "# samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 502 # power points 4800\n",
        "# channels 16\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "(664, 320)"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "0.72891566265060237"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "[<matplotlib.lines.Line2D at 0x114186990>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHBrpoYe4cwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11b2f7290>"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/X.mmap\n",
      "mmX = np.memmap('/tmp/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_shape = X.shape\n",
      "clients['X_shape'] = X_shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('/tmp/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import os\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn import svm\n",
      "            from sklearn.pipeline import Pipeline\n",
      "            from sklearn.preprocessing import StandardScaler\n",
      "            svc_clf = svm.SVC(C=70, probability=True)\n",
      "            nrm = StandardScaler()\n",
      "            est = Pipeline([('norm', nrm), ('svc', svc_clf)])\n",
      "\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-5 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf].copy(), y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf].copy())[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf].copy())[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, os.getpid(), args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'pid':os.getpid(),\n",
      "                    'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 100)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'pratio': 1,\n",
      "    'svc__C': hp.loguniform('svc__C', np.log(0.01), np.log(100.)),\n",
      "    'svc__kernel': 'linear', #'sigmoid',# # , 'rbf']),\n",
      "#     'svc__gamma': hp.lognormal('svm_gamma', 0, 1),\n",
      "#     'svc__coef0': hp.lognormal('svc__coef0', 0, 1),\n",
      "#     'svc__shrinking': False,\n",
      "#     'svc__tol': hp.loguniform('svc__tol', np.log(1e-4), np.log(1e-2)),\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:152]: \u001b[0m{'nf': 22.0, 'svc__C': 0.01444454605031127}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:152]: \u001b[0m{'nf': 16.0, 'svc__C': 0.011004493759453504}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:152]: \u001b[0m{'nf': 18.0, 'svc__C': 0.012314140200072128}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:152]: \u001b[0m{'nf': 168.0, 'svc__C': 0.01189213723654311}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:152]: \u001b[0m{'nf': 276.0, 'svc__C': 16.404797368963067}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:152]: \u001b[0m{'nf': 57.0, 'svc__C': 0.059273522584821006}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:152]: \u001b[0m{'nf': 16.0, 'svc__C': 0.02012373027467772}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:152]: \u001b[0m{'nf': 16.0, 'svc__C': 0.015494710665886055}"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.928260869565 0.90134863124 3079 {'svc__kernel': 'linear', 'svc__C': 0.059273522584821006, 'nf': 57.0, 'pratio': 1}\r\n",
        "0.924275362319 0.901821658615 3079 {'svc__kernel': 'linear', 'svc__C': 0.1824011363027172, 'nf': 52.0, 'pratio': 1}\r\n",
        "0.923007246377 0.898601046699 3079 {'svc__kernel': 'linear', 'svc__C': 0.05240363846153534, 'nf': 58.0, 'pratio': 1}\r\n",
        "0.921739130435 0.90845410628 3079 {'svc__kernel': 'linear', 'svc__C': 0.09376531882041579, 'nf': 61.0, 'pratio': 1}\r\n",
        "0.918297101449 0.907145732689 3079 {'svc__kernel': 'linear', 'svc__C': 0.5651165768018234, 'nf': 55.0, 'pratio': 1}\r\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = float(l[0])\n",
      "    train_score = float(l[1])\n",
      "    pid = int(l[2])\n",
      "    args = eval(''.join(l[3:]))\n",
      "    hyeropt_results.append((validate_score, train_score, pid, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "800"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Nt, NFF = Xt.shape\n",
      "assert NF == NFF\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 171,
       "text": [
        "(502, 320)"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (Nt, NF)\n",
      "mmXt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = Xt[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn import svm\n",
      "    from sklearn.pipeline import Pipeline\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "    svc_clf = svm.SVC(C=70, probability=True)\n",
      "    nrm = StandardScaler()\n",
      "    est = Pipeline([('norm', nrm), ('svc', svc_clf)])\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn.copy(), y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val.copy())[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test.copy())[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return roc_auc_score(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "pid2args_list = defaultdict(list)\n",
      "for res in hyeropt_results:\n",
      "    validation_score = res[0]\n",
      "    test_score = res[1]\n",
      "    pid = res[2]\n",
      "    args = res[3]\n",
      "    pid2args_list[pid].append((validation_score, args))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for v in pid2args_list.values():\n",
      "    print v[1]\n",
      "    for vv in v[:4]:\n",
      "        args_list.append(vv[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.924275362319, {'svc__kernel': 'linear', 'svc__C': 0.1824011363027172, 'nf': 52.0, 'pratio': 1})\n",
        "(0.88768115942, {'svc__kernel': 'linear', 'svc__C': 16.404797368963067, 'nf': 276.0, 'pratio': 1})\n",
        "(0.90018115942, {'svc__kernel': 'linear', 'svc__C': 0.02428217248125759, 'nf': 168.0, 'pratio': 1})\n",
        "(0.778804347826, {'svc__kernel': 'linear', 'svc__C': 0.01789815737414057, 'nf': 15.0, 'pratio': 1})\n",
        "(0.796376811594, {'svc__kernel': 'linear', 'svc__C': 0.010561614469297568, 'nf': 13.0, 'pratio': 1})\n",
        "(0.734420289855, {'svc__kernel': 'linear', 'svc__C': 0.03557220024296285, 'nf': 17.0, 'pratio': 1})\n",
        "(0.723188405797, {'svc__kernel': 'linear', 'svc__C': 0.022790862901953337, 'nf': 17.0, 'pratio': 1})\n",
        "(0.692028985507, {'svc__kernel': 'linear', 'svc__C': 0.03742719830581668, 'nf': 18.0, 'pratio': 1})\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 179,
       "text": [
        "[{'nf': 57.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.059273522584821006,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 52.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.1824011363027172,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 58.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.05240363846153534,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 61.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.09376531882041579,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 276.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 23.111102411527316,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 276.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 16.404797368963067,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 275.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.45316867801451505,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 271.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 13.165954917787275,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 168.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01189213723654311,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 168.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.02428217248125759,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 169.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.011184399766794181,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 172.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.030851292060746455,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 16.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.011004493759453504,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 15.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01789815737414057,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 22.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01077362311541191,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 24.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.03219579622916524,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 22.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01444454605031127,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 13.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.010561614469297568,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 14.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01152716206627307,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 11.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.010315994744334986,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 16.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.015494710665886055,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 17.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.03557220024296285,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 15.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.011719304857896106,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 15.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.04603425987974184,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 18.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.012314140200072128,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 17.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.022790862901953337,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 11.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.012309100981176956,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 11.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.027988893623160288,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 16.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.02012373027467772,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 18.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.03742719830581668,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 13.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.010432278778815621,\n",
        "  'svc__kernel': 'linear'},\n",
        " {'nf': 12.0,\n",
        "  'pratio': 1,\n",
        "  'svc__C': 0.01208956011600015,\n",
        "  'svc__kernel': 'linear'}]"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.645471014493\n",
        "0.758514492754\n",
        "0.54402173913\n",
        "0.396376811594\n",
        "0.637137681159\n",
        "0.485597826087\n",
        "0.721557971014\n",
        "0.615942028986\n",
        "0.423369565217\n",
        "0.884963768116\n",
        "0.882065217391\n",
        "0.511956521739\n",
        "0.78768115942"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.803351449275\n",
        "0.580615942029\n",
        "0.838405797101\n",
        "0.722373188406\n",
        "0.739492753623\n",
        "0.68097826087\n",
        "0.78115942029\n",
        "0.764130434783\n",
        "0.848188405797\n",
        "0.83115942029\n",
        "0.791123188406\n",
        "0.867391304348\n",
        "0.750724637681\n",
        "0.732608695652\n",
        "0.757789855072\n",
        "0.797282608696\n",
        "0.764855072464\n",
        "0.71856884058\n",
        "0.746557971014\n",
        "0.610144927536\n",
        "0.718115942029\n",
        "0.438586956522\n",
        "0.554166666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.81268115942"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.797826086957"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.771014492754\n",
        "0.817391304348\n",
        "0.510869565217\n",
        "0.623913043478\n",
        "0.452717391304\n",
        "0.860144927536\n",
        "0.888677536232\n",
        "0.850362318841\n",
        "0.778985507246\n",
        "0.797101449275\n",
        "0.865036231884\n",
        "0.784963768116\n",
        "0.688405797101\n",
        "0.852898550725\n",
        "0.766666666667\n",
        "0.700362318841\n",
        "0.797826086957"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.644202898551\n",
        "0.736684782609\n",
        "0.871195652174\n",
        "0.720652173913\n",
        "0.827626811594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.791123188406\n",
        "0.723822463768\n",
        "0.544565217391\n",
        "0.865760869565\n",
        "0.653442028986\n",
        "0.640942028986\n",
        "0.876721014493\n",
        "0.866485507246\n",
        "0.623731884058"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.70597826087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.50615942029\n",
        "0.822463768116"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.547463768116\n",
        "0.675724637681\n",
        "0.709601449275\n",
        "0.885416666667\n",
        "0.797010869565\n",
        "0.839492753623\n",
        "0.861775362319\n",
        "0.732065217391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.641485507246\n",
        "0.725724637681\n",
        "0.705072463768\n",
        "0.764492753623\n",
        "0.775\n",
        "0.823188405797\n",
        "0.646014492754\n",
        "0.845652173913\n",
        "0.645471014493\n",
        "0.899275362319\n",
        "0.569565217391\n",
        "0.775362318841\n",
        "0.821920289855\n",
        "0.739311594203\n",
        "0.84365942029\n",
        "0.713405797101\n",
        "0.511956521739\n",
        "0.839855072464\n",
        "0.589673913043\n",
        "0.851177536232"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.869565217391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.810326086957\n",
        "0.733695652174\n",
        "0.84365942029"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.907155797101\n",
        "0.891304347826\n",
        "0.474094202899\n",
        "0.687137681159\n",
        "0.791123188406\n",
        "0.784057971014\n",
        "0.745833333333\n",
        "0.817028985507\n",
        "0.780434782609\n",
        "0.780615942029\n",
        "0.728623188406\n",
        "0.722735507246\n",
        "0.889402173913\n",
        "0.627898550725"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.787137681159\n",
        "0.821920289855\n",
        "0.893115942029\n",
        "0.838405797101\n",
        "0.730525362319\n",
        "0.798369565217\n",
        "0.83134057971\n",
        "0.713405797101\n",
        "0.78097826087\n",
        "0.722826086957\n",
        "0.839855072464\n",
        "0.523369565217\n",
        "0.56231884058\n",
        "0.710688405797\n",
        "0.441847826087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.873369565217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.801630434783"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.748731884058\n",
        "0.67518115942\n",
        "0.532427536232\n",
        "0.623188405797\n",
        "0.760507246377\n",
        "0.737137681159\n",
        "0.8125\n",
        "0.790217391304\n",
        "0.442753623188\n",
        "0.838586956522\n",
        "0.771195652174\n",
        "0.711413043478"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.725\n",
        "0.788949275362\n",
        "0.688224637681\n",
        "0.818297101449\n",
        "0.822916666667\n",
        "0.814492753623\n",
        "0.770108695652\n",
        "0.658695652174\n",
        "0.849637681159\n",
        "0.820380434783\n",
        "0.800996376812\n",
        "0.846195652174\n",
        "0.803804347826\n",
        "0.668115942029\n",
        "0.522282608696\n",
        "0.662137681159"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.530797101449\n",
        "0.754438405797"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.551811594203\n",
        "0.786050724638\n",
        "0.702173913043\n",
        "0.842210144928\n",
        "0.441123188406\n",
        "0.634963768116\n",
        "0.539492753623\n",
        "0.56902173913\n",
        "0.827173913043\n",
        "0.878442028986\n",
        "0.845108695652\n",
        "0.773550724638\n",
        "0.655434782609\n",
        "0.745652173913\n",
        "0.621920289855\n",
        "0.817481884058\n",
        "0.740942028986\n",
        "0.730797101449\n",
        "0.925543478261\n",
        "0.807065217391\n",
        "0.826630434783\n",
        "0.841304347826\n",
        "0.853804347826\n",
        "0.871376811594\n",
        "0.863768115942"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.792119565217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.615579710145\n",
        "0.732246376812\n",
        "0.734963768116\n",
        "0.566485507246\n",
        "0.569112318841\n",
        "0.794746376812"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.344384057971\n",
        "0.447010869565\n",
        "0.814130434783"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.474456521739\n",
        "0.7125\n",
        "0.447101449275\n",
        "0.5625\n",
        "0.725362318841\n",
        "0.844565217391\n",
        "0.727355072464\n",
        "0.56268115942\n",
        "0.596376811594\n",
        "0.902717391304\n",
        "0.739673913043\n",
        "0.809782608696"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.717572463768\n",
        "0.727717391304\n",
        "0.869202898551\n",
        "0.783333333333\n",
        "0.761050724638\n",
        "0.875543478261\n",
        "0.748913043478\n",
        "0.741032608696\n",
        "0.836956521739\n",
        "0.771195652174\n",
        "0.815217391304\n",
        "0.745652173913\n",
        "0.586775362319\n",
        "0.68097826087\n",
        "0.748550724638\n",
        "0.58143115942\n",
        "0.414583333333"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.503442028986\n",
        "0.570108695652"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.759239130435\n",
        "0.840579710145\n",
        "0.691666666667\n",
        "0.238586956522\n",
        "0.486956521739\n",
        "0.79393115942\n",
        "0.647101449275\n",
        "0.729528985507\n",
        "0.75606884058\n",
        "0.546557971014\n",
        "0.679891304348\n",
        "0.740036231884\n",
        "0.693297101449\n",
        "0.715217391304\n",
        "0.661775362319\n",
        "0.702536231884\n",
        "0.795289855072\n",
        "0.867663043478\n",
        "0.803260869565\n",
        "0.512137681159\n",
        "0.840851449275\n",
        "0.669384057971\n",
        "0.705253623188\n",
        "0.69347826087\n",
        "0.702536231884\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_count == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "0.72473958333333333"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 141107-GBC-combine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    }
   ],
   "metadata": {}
  }
 ]
}