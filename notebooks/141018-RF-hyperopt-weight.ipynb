{
 "metadata": {
  "name": "",
  "signature": "sha256:628eb441762614bd376587a37c41b4fe91be35e12d2584854e5f028a6d81a92e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 588
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 589
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 590
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 591
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 592,
       "text": [
        "(184, 240)"
       ]
      }
     ],
     "prompt_number": 592
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 593,
       "text": [
        "(480, 240)"
       ]
      }
     ],
     "prompt_number": 593
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 594
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 595
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_1 0.277108433735 184 480\n",
        "Dog_1 0.047619047619 4 80\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 596,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 596
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 597
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 598
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 599,
       "text": [
        "(664, 240)"
       ]
      }
     ],
     "prompt_number": 599
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 600,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 600
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 601,
       "text": [
        "0.8012048192771084"
       ]
      }
     ],
     "prompt_number": 601
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x119f18590>"
       ]
      }
     ],
     "prompt_number": 602
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 603
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 604
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 605,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 605
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients.scatter('engineid', range(Ncores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 606,
       "text": [
        "<AsyncResult: finished>"
       ]
      }
     ],
     "prompt_number": 606
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['latencies'] = latencies\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 607
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 608
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split data to training and validation. Randomly pick one positive segment for validation and a matching number of negative segments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"\n",
      "    N - total number of samples.\n",
      "    pratio - 0: no validation, 1: use all training data, 0<pratio<1: bootstrap from all training data\n",
      "    \"\"\"\n",
      "    if pratio == 0:\n",
      "        return range(N), []\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have at least one segment in train and validate\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "#         testp *= pratio\n",
      "        ntestp = len(testp)\n",
      "        boot_ntestp = int(ntestp*pratio)\n",
      "        w = np.ones(ntestp)/float(ntestp)\n",
      "        testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "                 for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 609
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will find args which will optimize AUC for a given train and validation data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "def target(args, X_trn, y_trn, latencies_trn, X_val, y_val):\n",
      "    est = RandomForestClassifier()\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                  for k, v in args.iteritems() if k not in ['nf', 'pratio', 'alpha'])\n",
      "    est.set_params(**params)\n",
      "\n",
      "    nf = int(args['nf'])\n",
      "    sample_weight = np.exp(args['alpha']*(6.-latencies_trn))\n",
      "    \n",
      "    est.fit(X_trn[:,:nf], y_trn, sample_weight)\n",
      "\n",
      "    y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "    y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    train_score = roc_auc_score(y_trn, y_train)\n",
      "    validate_score = roc_auc_score(y_val, y_validate)\n",
      "    \n",
      "    return train_score, validate_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 610
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    latencies_trn = latencies[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            train_score, validate_score = target(args, X_trn, y_trn, latencies_trn, X_val, y_val)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, engineid, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 611
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'pratio': 1,\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'alpha': 0, # hp.loguniform('alpha', np.log(1e-3), np.log(1.)),\n",
      "    'n_estimators': hp.qloguniform('n_estimators', np.log(50), np.log(4000), 1),\n",
      "    'criterion': hp.choice('criterion',['gini', 'entropy']),\n",
      "    'max_depth': hp.choice('max_depth',\n",
      "            [None, hp.qlognormal('max_depth_int', np.log(5), 1, 1)]),\n",
      "    'min_samples_split': hp.qloguniform('min_samples_split', np.log(1.), np.log(5.), 1),\n",
      "    'min_samples_leaf': hp.qloguniform('min_samples_leaf', np.log(1.), np.log(5.), 1),\n",
      "    'bootstrap': hp.choice('bootstrap',[False, True]),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 612
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 613
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:20]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 1,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 2.0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 4.0,\n",
        " 'n_estimators': 62.0,\n",
        " 'nf': 186.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:20]: \u001b[0m\n",
        "{'bootstrap': 0,\n",
        " 'criterion': 1,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 33.0,\n",
        " 'min_samples_leaf': 2.0,\n",
        " 'min_samples_split': 2.0,\n",
        " 'n_estimators': 396.0,\n",
        " 'nf': 156.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:20]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 2132.0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 3.0,\n",
        " 'n_estimators': 210.0,\n",
        " 'nf': 93.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:20]: \u001b[0m\n",
        "{'bootstrap': 0,\n",
        " 'criterion': 0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 2.0,\n",
        " 'n_estimators': 320.0,\n",
        " 'nf': 11.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:20]: \u001b[0m\n",
        "{'bootstrap': 0,\n",
        " 'criterion': 0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 2.0,\n",
        " 'min_samples_split': 5.0,\n",
        " 'n_estimators': 2127.0,\n",
        " 'nf': 11.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:20]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 1,\n",
        " 'max_depth': 1,\n",
        " 'max_depth_int': 8.0,\n",
        " 'min_samples_leaf': 1.0,\n",
        " 'min_samples_split': 5.0,\n",
        " 'n_estimators': 127.0,\n",
        " 'nf': 81.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:20]: \u001b[0m\n",
        "{'bootstrap': 0,\n",
        " 'criterion': 0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 3.0,\n",
        " 'min_samples_split': 2.0,\n",
        " 'n_estimators': 522.0,\n",
        " 'nf': 11.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:20]: \u001b[0m\n",
        "{'bootstrap': 1,\n",
        " 'criterion': 0,\n",
        " 'max_depth': 0,\n",
        " 'min_samples_leaf': 2.0,\n",
        " 'min_samples_split': 4.0,\n",
        " 'n_estimators': 50.0,\n",
        " 'nf': 137.0}"
       ]
      }
     ],
     "prompt_number": 614
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.983695652174 1.0 [5] {'bootstrap': True, 'nf': 81.0, 'min_samples_leaf': 1.0, 'n_estimators': 127.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 5.0, 'alpha': 0, 'max_depth': 8.0}\r\n",
        "0.98115942029 1.0 [5] {'bootstrap': True, 'nf': 83.0, 'min_samples_leaf': 3.0, 'n_estimators': 124.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'max_depth': 8.0}\r\n",
        "0.978623188406 1.0 [5] {'bootstrap': True, 'nf': 85.0, 'min_samples_leaf': 1.0, 'n_estimators': 583.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 4.0, 'alpha': 0, 'max_depth': 10.0}\r\n",
        "0.978260869565 1.0 [5] {'bootstrap': True, 'nf': 87.0, 'min_samples_leaf': 3.0, 'n_estimators': 2746.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'max_depth': 12.0}\r\n",
        "0.978079710145 1.0 [5] {'bootstrap': True, 'nf': 97.0, 'min_samples_leaf': 1.0, 'n_estimators': 81.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 5.0, 'alpha': 0, 'max_depth': None}\r\n"
       ]
      }
     ],
     "prompt_number": 615
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = defaultdict(list)\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    engineid = l[2]\n",
      "    args = eval(''.join(l[3:]))\n",
      "    hyeropt_results[engineid].append((validate_score, train_score, args))\n",
      "fp.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 616
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 617,
       "text": [
        "(502, 240)"
       ]
      }
     ],
     "prompt_number": 617
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: /tmp/Xt.mmap: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 618
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 619
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 620
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=0)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    latencies_trn = latencies[sample_train]\n",
      "    \n",
      "    if sample_validate:\n",
      "        X_val = X[sample_validate,:NF]\n",
      "        y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    est = RandomForestClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio', 'alpha'])\n",
      "    est.set_params(**params)\n",
      "    sample_weight = np.exp(args['alpha']*(6.-latencies_trn))\n",
      "\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn, sample_weight)\n",
      "\n",
      "        if sample_validate:\n",
      "            y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        else:\n",
      "            y_val_est = None\n",
      "\n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    if sample_validate:\n",
      "        return roc_auc_score(y_val, y_val_est)\n",
      "    else:\n",
      "        return 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 621
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: ../data-cache/Dog_1_test.spkl: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 622
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for i in range(100):\n",
      "    for results in hyeropt_results.itervalues():\n",
      "        args = results[i][2]\n",
      "        print results[i][0],args\n",
      "        args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.861775362319 {'n_estimators': 522.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': False, 'max_depth': None, 'nf': 11.0, 'min_samples_leaf': 3.0}\n",
        "0.97509057971 {'n_estimators': 50.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 4.0, 'alpha': 0, 'bootstrap': True, 'max_depth': None, 'nf': 137.0, 'min_samples_leaf': 2.0}\n",
        "0.81865942029 {'n_estimators': 2127.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 5.0, 'alpha': 0, 'bootstrap': False, 'max_depth': None, 'nf': 11.0, 'min_samples_leaf': 2.0}\n",
        "0.983695652174 {'n_estimators': 127.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 5.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 8.0, 'nf': 81.0, 'min_samples_leaf': 1.0}\n",
        "0.89347826087 {'n_estimators': 210.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 2132.0, 'nf': 93.0, 'min_samples_leaf': 1.0}\n",
        "0.852536231884 {'n_estimators': 320.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': False, 'max_depth': None, 'nf': 11.0, 'min_samples_leaf': 1.0}\n",
        "0.904347826087 {'n_estimators': 62.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 4.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 2.0, 'nf': 186.0, 'min_samples_leaf': 1.0}\n",
        "0.966938405797 {'n_estimators': 396.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': False, 'max_depth': 33.0, 'nf': 156.0, 'min_samples_leaf': 2.0}\n",
        "0.860688405797 {'n_estimators': 74.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'bootstrap': True, 'max_depth': None, 'nf': 11.0, 'min_samples_leaf': 4.0}\n",
        "0.971376811594 {'n_estimators': 123.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 1.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 8.0, 'nf': 58.0, 'min_samples_leaf': 1.0}\n",
        "0.817572463768 {'n_estimators': 3932.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'bootstrap': False, 'max_depth': None, 'nf': 10.0, 'min_samples_leaf': 2.0}\n",
        "0.98115942029 {'n_estimators': 124.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 8.0, 'nf': 83.0, 'min_samples_leaf': 3.0}\n",
        "0.892663043478 {'n_estimators': 217.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 30.0, 'nf': 155.0, 'min_samples_leaf': 1.0}\n",
        "0.850543478261 {'n_estimators': 1930.0, 'criterion': 'gini', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': False, 'max_depth': None, 'nf': 11.0, 'min_samples_leaf': 1.0}\n",
        "0.89981884058 {'n_estimators': 1947.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 3.0, 'alpha': 0, 'bootstrap': True, 'max_depth': 2.0, 'nf': 169.0, 'min_samples_leaf': 1.0}\n",
        "0.965217391304 {'n_estimators': 189.0, 'criterion': 'entropy', 'pratio': 1, 'min_samples_split': 2.0, 'alpha': 0, 'bootstrap': False, 'max_depth': 136.0, 'nf': 198.0, 'min_samples_leaf': 1.0}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 623,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 623
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 624
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "#     print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 625
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    if not sample_validate:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 626
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "if np.any(np.isnan(y_est)):\n",
      "    print np.sum(y_count == 0),len(y_count)\n",
      "else:\n",
      "    y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "    y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "    print roc_auc_score(y_no_overlap, y_est_no_overlap)\n",
      "    with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "        pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "664 664\n"
       ]
      }
     ],
     "prompt_number": 627
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l ../data-cache/*_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 udi  staff   66384 Oct 18 10:46 ../data-cache/Dog_1_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff  130128 Oct 18 10:38 ../data-cache/Dog_2_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff  118224 Oct 18 10:29 ../data-cache/Dog_3_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff  128848 Oct 18 09:25 ../data-cache/Dog_4_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff   26560 Oct 18 08:59 ../data-cache/Dog_5_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff   27072 Oct 18 08:52 ../data-cache/Patient_1_test.spkl\r\n",
        "-rw-r--r--  1 udi  staff   21312 Oct 18 08:46 ../data-cache/Patient_2_test.spkl\r\n"
       ]
      }
     ],
     "prompt_number": 628
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - the following line will not crash"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../submissions/141018-predict.2.csv','w') as fpout:\n",
      "    print >>fpout,'clip,preictal'    \n",
      "    for target in ['Dog_1', 'Dog_2', 'Dog_3', 'Dog_4', 'Dog_5', 'Patient_1', 'Patient_2']:\n",
      "        with open('../data-cache/%s_test.spkl'%target,'rb') as fp:\n",
      "            y_proba = pickle.load(fp)\n",
      "        # write results\n",
      "        for i,p in enumerate(y_proba):\n",
      "            print >>fpout,'%s_test_segment_%04d.mat,%.15f' % (target, i+1, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 629
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/*_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 630
    }
   ],
   "metadata": {}
  }
 ]
}