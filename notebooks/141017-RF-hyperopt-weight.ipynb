{
 "metadata": {
  "name": "",
  "signature": "sha256:1cb5c632fa816ffa5d6005dd0a95ab60cda32c5ab34a7284b465bd1f48ead2a5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_5'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['latencies'] = latencies\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split data to training and validation. Randomly pick one positive segment for validation and a matching number of negative segments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"\n",
      "    N - total number of samples.\n",
      "    pratio - 0: no validation, 1: use all training data, 0<pratio<1: bootstrap from all training data\n",
      "    \"\"\"\n",
      "    if pratio == 0:\n",
      "        return range(N), []\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have at least one segment in train and validate\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "#         testp *= pratio\n",
      "        ntestp = len(testp)\n",
      "        boot_ntestp = int(ntestp*pratio)\n",
      "        w = np.ones(ntestp)/float(ntestp)\n",
      "        testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "                 for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will find args which will optimize AUC for a given train and validation data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "def target(args, X_trn, y_trn, latencies_trn, X_val, y_val):\n",
      "    est = RandomForestClassifier()\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                  for k, v in args.iteritems() if k not in ['nf', 'pratio', 'alpha'])\n",
      "    est.set_params(**params)\n",
      "\n",
      "    nf = int(args['nf'])\n",
      "    sample_weight = np.exp(args['alpha']*(6.-latencies_trn))\n",
      "    \n",
      "    est.fit(X_trn[:,:nf], y_trn, sample_weight)\n",
      "\n",
      "    y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "    y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    train_score = roc_auc_score(y_trn, y_train)\n",
      "    validate_score = roc_auc_score(y_val, y_validate)\n",
      "    \n",
      "    return train_score, validate_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    latencies_trn = latencies[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            train_score, validate_score = target(args, X_trn, y_trn, latencies_trn, X_val, y_val)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'pratio': 1,\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'alpha': hp.loguniform('alpha', np.log(1e-5), np.log(1.)),\n",
      "    'n_estimators': hp.qloguniform('n_estimators', np.log(50), np.log(4000), 1),\n",
      "    'criterion': hp.choice('criterion',['gini', 'entropy']),\n",
      "    'max_depth': hp.choice('max_depth',\n",
      "            [None, hp.qlognormal('max_depth_int', np.log(5), 1, 1)]),\n",
      "    'min_samples_split': hp.qloguniform('min_samples_split', np.log(1.), np.log(5.), 1),\n",
      "    'min_samples_leaf': hp.qloguniform('min_samples_leaf', np.log(1.), np.log(5.), 1),\n",
      "    'bootstrap': hp.choice('bootstrap',[False, True]),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    args = eval(''.join(l[2:]))\n",
      "    hyeropt_results.append((validate_score, train_score, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=0)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    latencies_trn = latencies[sample_train]\n",
      "    \n",
      "    if sample_validate:\n",
      "        X_val = X[sample_validate,:NF]\n",
      "        y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    est = RandomForestClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio', 'alpha'])\n",
      "    est.set_params(**params)\n",
      "    sample_weight = np.exp(args['alpha']*(6.-latencies_trn))\n",
      "\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn, sample_weight)\n",
      "\n",
      "        if sample_validate:\n",
      "            y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        else:\n",
      "            y_val_est = None\n",
      "\n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    if sample_validate:\n",
      "        return roc_auc_score(y_val, y_val_est)\n",
      "    else:\n",
      "        return 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for res in hyeropt_results:\n",
      "    args = res[2]\n",
      "    print args\n",
      "    args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "#     print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    if not sample_validate:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "if np.any(np.isnan(y_est)):\n",
      "    print np.sum(y_count == 0),len(y_count)\n",
      "else:\n",
      "    y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "    y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "    print roc_auc_score(y_no_overlap, y_est_no_overlap)\n",
      "    with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "        pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140929-target-combine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l ../data-cache/*_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../submissions/141017-predict.2.csv','w') as fpout:\n",
      "    print >>fpout,'clip,preictal'    \n",
      "    for target in ['Dog_1', 'Dog_2', 'Dog_3', 'Dog_4', 'Dog_5', 'Patient_1', 'Patient_2']:\n",
      "        with open('../data-cache/%s_test.spkl'%target,'rb') as fp:\n",
      "            y_proba = pickle.load(fp)\n",
      "        # write results\n",
      "        for i,p in enumerate(y_proba):\n",
      "            print >>fpout,'%s_test_segment_%04d.mat,%.15f' % (target, i+1, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!rm ../data-cache/*_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}