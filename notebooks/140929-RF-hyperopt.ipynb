{
 "metadata": {
  "name": "",
  "signature": "sha256:42d5276adb64f810e3e7f26b0621ba75faf46300726058951b46120b17f26d4f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_3'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8.5_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LOCAL_HOSTNAME=!hostname\n",
      "if LOCAL_HOSTNAME[0].startswith('ip-'):\n",
      "    !aws s3 cp s3://udikaggle/sezure/{FEATURES}.tgz data-cache/\n",
      "    !tar xfz data-cache/{FEATURES}.tgz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "(552, 240)"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "(11040, 240)"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_3 0.047619047619 552 11040\n",
        "Dog_3 0.047619047619 12 240\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "(11592, 240)"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "0.96014492753623193"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "[<matplotlib.lines.Line2D at 0x1159c71d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x116534f90>"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn.ensemble import RandomForestClassifier\n",
      "            est = RandomForestClassifier()\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'pratio': 1,\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'n_estimators': hp.qloguniform('learning_rate', np.log(50), np.log(4000), 1),\n",
      "    'criterion': hp.choice('criterion',['gini', 'entropy']),\n",
      "    'max_depth': hp.choice('max_depth',\n",
      "            [None, hp.qlognormal('max_depth_int', np.log(5), 1, 1)]),\n",
      "    'min_samples_split': hp.qloguniform('min_samples_split', np.log(1.), np.log(5.), 1),\n",
      "    'min_samples_leaf': hp.qloguniform('min_samples_leaf', np.log(1.), np.log(5.), 1),\n",
      "    'bootstrap': hp.choice('bootstrap',[False, True]),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    args = eval(''.join(l[2:]))\n",
      "    hyeropt_results.append((validate_score, train_score, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    est = RandomForestClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return roc_auc_score(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for res in hyeropt_results:\n",
      "    args = res[2]\n",
      "    print args\n",
      "    args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_count == 0),len(y_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140929-target-combine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}