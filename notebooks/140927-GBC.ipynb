{
 "metadata": {
  "name": "",
  "signature": "sha256:b9b41b1b3cbb9084538a15c63d88b8031c005a51dfbf9c28b976432e5f19693f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 656
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 657
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 658
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8.5_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 659
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LOCAL_HOSTNAME=!hostname\n",
      "if LOCAL_HOSTNAME[0].startswith('ip-'):\n",
      "    !aws s3 cp s3://udikaggle/sezure/{FEATURES}.tgz data-cache/\n",
      "    !tar xfz data-cache/{FEATURES}.tgz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 660
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 661,
       "text": [
        "(184, 240)"
       ]
      }
     ],
     "prompt_number": 661
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 662,
       "text": [
        "(3680, 240)"
       ]
      }
     ],
     "prompt_number": 662
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 663
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 664
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_1 0.047619047619 184 3680\n",
        "Dog_1 0.047619047619 4 80\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 665,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 665
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 666
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 667
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 668,
       "text": [
        "(3864, 240)"
       ]
      }
     ],
     "prompt_number": 668
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 669,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 669
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 670,
       "text": [
        "0.95238095238095233"
       ]
      }
     ],
     "prompt_number": 670
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 671,
       "text": [
        "[<matplotlib.lines.Line2D at 0x11ad11350>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuUlHed5/F3XfsK3dzSEKDTBAgSJAlkJrIGk7j2tAQz\nibNnPTGuyYxz1mQXSdQ5owmeUXPW45p4xtVhck7CepvoiMkYHUU3HExr0LSjJNhAKtzCJYR7c+0G\n+lbX/eP3dP8eyu6uanioerrq8zqnDvU89VTVrz9dfJ+nvr+nqkFERERERERERERERERERERERERE\nRMawZcAuYA/w6DDbrHZu3wYsctbNA7a4Ll3AI1d0pCIi4okQsBdoAiLAVmB+1jbLgRed6+8C/jDE\n4wSBY8DMKzJKEREZlWCO22/BFP8DQAJ4Drgna5u7gWed65uAeqAha5tmYB9w6DLGKiIiHslV/Kdz\nccE+7KzLtc2MrG0+DKy9lAGKiIj3chX/TJ6PExjhflHgL4Ef5TsoERG5ssI5bj/CxX36mZgj+5G2\nmeGsG3An8Efg5FBP8IMf/CDT0JDdJRIRkZEcO3Zs3/333z/nUu+fq/hvBuZiJnyPAvcC92Vtsw5Y\niZkPWAJ0Ah2u2+8DfjjcEzQ0NLB48eJRDbpUPfHEEzz22GPFHoYvKAtLWVjKwmpvb599OffPVfyT\nmMK+AXPmz7eBncBDzu1rMGf6LMdMDHcDH3PdvwYz2fvxyxlkuTh48GCxh+AbysJSFpay8E6u4g+w\n3rm4rclaXjnMfbuByaMdlIiIXFm5JnylgD7ykY8Uewi+oSwsZWEpC+9kn6VTcK2trRn1/EVERqe9\nvZ3m5uZLruE68veRtra2Yg/BN5SFpSwsZeEdFX8RkTKkto+IyBikto+IiIyair+PqJ9pKQtLWVjK\nwjsq/iIiZUg9fxGRMUg9fxERGTUVfx9RP9NSFpaysJSFd1T8RUTKkHr+IiJjkHr+IiIyair+PqJ+\npqUsLGVhKQvvqPiLiJQh9fxFRMYg9fxFRGTUVPx9RP1MS1lYysJSFt5R8RcRKUPq+YuIjEHq+YuI\nyKip+PuI+pmWsrCUhaUsvJNP8V8G7AL2AI8Os81q5/ZtwCLX+nrgBWAnsANYMtSd95/uzXO4IiLi\nhVzFPwQ8hdkBXA/cB8zP2mY5MAeYCzwIPO267Z+AF5373IDZCfyJw+f6RjvukrR06dJiD8E3lIWl\nLCxl4Z1cxf8WYC9wAEgAzwH3ZG1zN/Csc30T5mi/AagD3gN8x7ktCXQN9STxZGaUwxYRkcuRq/hP\nBw65lg8763JtMwOYBZwEvgu0A98Eqod6kr5kOv8RlzD1My1lYSkLS1l4J5zj9nwPybNPN8o4j70Y\nWAm8BnwDeAz4Qvadn/7SZ3njhusAqKurY+HChYNv7wZ+2Vour+UBfhlPMZdjsZivxlPM5Vgs5qvx\nFHK5ra2NtWvXAtDY2EhLSwuXI9c5okuAxzE9f4BVQBp40rXNM8BGTEsIzOTw7c5j/x7zDgBgKab4\n3+V+gtbW1szu4NXcd9PUS/oBRETK0ZU+z38zZiK3CYgC9wLrsrZZBzzgXF8CdAIdwHFMO+g657Zm\nYPtQTxJPqecvIlJIuYp/EtO22YA5VfN5zBk7DzkXMGfz7MdMDK8BVrju/zDwA8wpoDcA/3uoJ+lX\nzx9QP9NNWVjKwlIW3snV8wdY71zc1mQtrxzmvtuAP8/1BCr+IiKF5YtP+MZTKv6gc5jdlIWlLCxl\n4R1fFH8d+YuIFJZPir8mfEH9TDdlYSkLS1l4xx/FX20fEZGC8kXxj6vtA6if6aYsLGVhKQvv+KL4\n68hfRKSw/FH81fMH1M90UxaWsrCUhXd8Uvx15C8iUki+KP46z99QP9NSFpaysJSFd3xR/HXkLyJS\nWCr+PqJ+pqUsLGVhKQvv+KL4pzKQSmvSV0SkUHxR/EFH/6B+ppuysJSFpSy8o+IvIlKG/FP8dcaP\n+pkuysJSFpay8I5vin9cH/QSESkY3xR/Hfmrn+mmLCxlYSkL7/in+KvnLyJSMCr+PqJ+pqUsLGVh\nKQvv+Kb4x1Pq+YuIFIpvir+O/NXPdFMWlrKwlIV3/FP8NeErIlIw/in+OvJXP9NFWVjKwlIW3smn\n+C8DdgF7gEeH2Wa1c/s2YJFr/QHgdWAL8OpIT6I/5SgiUjjhHLeHgKeAZuAI8BqwDtjp2mY5MAeY\nC7wLeBpY4tyWAe4AzuQaSJ8mfNXPdFEWlrKwlIV3ch353wLsxRzBJ4DngHuytrkbeNa5vgmoBxpc\ntwfyGYiO/EVECidX8Z8OHHItH3bW5btNBmgFNgMfH+mJNOGrfqabsrCUhaUsvJOr7ZNvL2a4o/ul\nwFFgCvASZu7gleyN9j//JL9sn0XXxjrq6upYuHDh4Nu7gV+2lstreYBfxlPM5Vgs5qvxFHM5Fov5\najyFXG5ra2Pt2rUANDY20tLSwuXI1ZJZAjyOmfQFWAWkgSdd2zwDbMS0hMAU+NuBjqzH+iJwAfia\ne2Vra2vmsfYAzXMm8Nk7mkY3ehGRMtXe3k5zc3NebfWh5Gr7bMZM5DYBUeBezISv2zrgAef6EqAT\nU/irgXHO+hqgBYgN90T9mvAVESmYXMU/CawENgA7gOcxZ/o85FwAXgT2YyaG1wArnPVTMS2erZiJ\n4F8AvxzuiRLq+auf6aIsLGVhKQvv5Or5A6x3Lm5rspZXDnG//cBN+Q5E3+0jIlI4vvmEb1xH/jqH\n2UVZWMrCUhbe8U3xT+jIX0SkYHxT/PUhL/Uz3ZSFpSwsZeEd/xR/HfmLiBSMj4q/jvzVz7SUhaUs\nLGXhHR8Vfx35i4gUim+Kv87zVz/TTVlYysJSFt7xUfHXkb+ISKH4p/inM6Qz5b0DUD/TUhaWsrCU\nhXd8UfwjIfPdRDr6FxEpDF8U/2jIDKPcz/hRP9NSFpaysJSFd3xS/M2Rv874EREpDJ8Ufx35g/qZ\nbsrCUhaWsvCOL4r/YM8/qSN/EZFC8EXx15G/oX6mpSwsZWEpC+/4pPir5y8iUkg+Kf5mGOX+KV/1\nMy1lYSkLS1l4xxfFP6IjfxGRgvJF8VfP31A/01IWlrKwlIV3fFL8deQvIlJIvij+kbB6/qB+ppuy\nsJSFpSy844viryN/EZHC8knxV88f1M90UxaWsrCUhXfyKf7LgF3AHuDRYbZZ7dy+DViUdVsI2AL8\nfLgnsEf+5V38RUQKJVfxDwFPYXYA1wP3AfOztlkOzAHmAg8CT2fd/klgBzBsT2fwyL/Mv95B/UxL\nWVjKwlIW3slV/G8B9gIHgATwHHBP1jZ3A8861zcB9UCDszwDs3P4FhAY7kkGv9snXd7FX0SkUHIV\n/+nAIdfyYWddvtt8HfgMMGI/J6KeP6B+ppuysJSFpSy8E85xe76H4tlH9QHgLuAEpt9/x0h3fvYr\nj3EkOZ5ftlfDlpksXLhw8O3dwC9by+W1PMAv4ynmciwW89V4irkci8V8NZ5CLre1tbF27VoAGhsb\naWlp4XIM24pxLAEex/T8AVZhjuKfdG3zDLAR0xICMzl8B/AIcD+QBCqB8cCPgQfcT9Da2po5UXMN\n/+eVg7TMncjf337NJf4oIiLlo729nebm5lw1fFi52j6bMRO5TUAUuBdYl7XNOmxBXwJ0AseBzwEz\ngVnAh4Ffk1X4B+hsHxGRwspV/JPASmAD5oyd54GdwEPOBeBFYD9mYngNsGKYx8p9tk+Zf8hL/UxL\nWVjKwlIW3snV8wdY71zc1mQtr8zxGL9xLkOKhnXkLyJSSL74hG9k8Pv8y/vIX+cwW8rCUhaWsvCO\nL4q/ev4iIoXlk+Kvnj+on+mmLCxlYSkL7/ii+A9+wrfMi7+ISKH4ovjrWz0N9TMtZWEpC0tZeMcn\nxV89fxGRQvJJ8dfZPqB+ppuysJSFpSy844viP9Dzjyd15C8iUgi+KP7us30ymfI9+lc/01IWlrKw\nlIV3fFH8Q8EAVZEgGaAnoaN/EZErzRfFH6C+0nzTRGdvosgjKR71My1lYSkLS1l4xz/Fv2qg+CeL\nPBIRkdLnn+JfGQHgbF/5Fn/1My1lYSkLS1l4xz/FX0f+IiIF45/ir56/+pkuysJSFpay8I5/iv/A\nkX8Zt31ERArFR8Xf9PzLue2jfqalLCxlYSkL7/io+KvnLyJSKP4p/pVq+6ifaSkLS1lYysI7/in+\nVZrwFREpFN8U//EVYQLAuf4UqXR5fr+P+pmWsrCUhaUsvOOb4h8KBhjvtH66yrj1IyJSCL4p/qBJ\nX/UzLWVhKQtLWXgnn+K/DNgF7AEeHWab1c7t24BFzrpKYBOwFdgBfCXXE00YPNdffX8RkSspV/EP\nAU9hdgDXA/cB87O2WQ7MAeYCDwJPO+v7gPcCNwE3ONdHbNhNdM71P3ounu/4S4r6mZaysJSFpSy8\nk6v43wLsBQ4ACeA54J6sbe4GnnWubwLqgQZnucf5N4rZkZwZ6cnmX1UDwBvHL+QcuIiIXLpcxX86\ncMi1fNhZl2ubGc71EKbt0wG8jGn/DOuGabUAvH78Qln+RS/1My1lYSkLS1l4J5zj9nwrcGCY+6Uw\nbZ86YANwB7Ax+84rVqygsbGRDHD2zW7ONVzL8bvmMm1cxeAve+DtnpbLY3mAX8ZTzOVYLOar8RRz\nORaL+Wo8hVxua2tj7dq1ADQ2NtLS0sLlyC7a2ZYAj2N6/gCrgDTwpGubZzAF/TlneRdwO+Zo3+3z\nQC/wj+6Vra2tmcWLFw8uf/Gl/fz+7S7+/rZGWq6blO/PISJSVtrb22lubs5Vw4eVq+2zGTOR24Tp\n298LrMvaZh3wgHN9CdCJKfyTMf1/gCrgL4AtuQZ0w1TT+nn6D0f45qYjuTYXEZFLkKv4J4GVmJbN\nDuB5YCfwkHMBeBHYj5kYXgOscNZPA36N6flvAn4O/CrXgG67tp5r6ivpjqf4UewE3fHUqH6gsUz9\nTEtZWMrCUhbeydXzB1jvXNzWZC2vHOJ+MWDxEOtHNKUmyjf/63z++ws7OdjZR8f5ONdOqhrtw4iI\nyAh89Qlft4baKAAdF8rnnH+dw2wpC0tZWMrCOyr+IiJlyLfF/6px5tO+Hef7izySwlE/01IWlrKw\nlIV3fFv8G2orAOi4oO/5ERHxmo+Lv2n7nCijto/6mZaysJSFpSy84/vir56/iIj3fFv8J1SHiQQD\ndPUl6U2Ux7n+6mdaysJSFpay8I5vi38wEGBKGbZ+REQKwbfFH8qv9aN+pqUsLGVhKQvv+Lr4XzOh\nEoDYMX2/v4iIl3xd/Jc2me+F27i/syy+31/9TEtZWMrCUhbe8XXxf+fUGiZVR+i4EGf3yZ7cdxAR\nkbz4uvgHAwFum2WO/n8cO0EyXdpH/+pnWsrCUhaWsvCOr4s/wPuvm0QoAL95q5NV6/eSKvEdgIhI\nIfi++F87qYp//MBc6ivDbDt2gV/tHfFvwI9p6mdaysJSFpay8I7viz/Agqm1PPgu83fjv9d+jANn\ne8tiAlhE5Eq55L//6JXsv+E7nFQ6w//8910cONsHQPOcCXzm9msIBIr+I4iIFNyV/hu+vhEKBvj8\n+2axtKmeinCQ1r1nWbfjVLGHJSIyJo2Z4g8ws76SLzTP4jO3NQLwzVePlNTf+FU/01IWlrKwlIV3\nxlTxH3DbtROYN6WaeCrDrhPdxR6OiMiYMyaLP8CChhoAtneUTvHXOcyWsrCUhaUsvDOGi38tUFrF\nX0SkUMZw8TdH/rtOdpfMB7/Uz7SUhaUsLGXhnXyL/zJgF7AHeHSYbVY7t28DFjnrZgIvA9uBN4BH\nLnmkWSZWR5g2LkpvIs1bZ3q9elgRkbKQT/EPAU9hdgDXA/cB87O2WQ7MAeYCDwJPO+sTwKeBBcAS\n4BND3PeSLZxqWj//9LtDdPaO/T/0rn6mpSwsZWEpC+/kU/xvAfYCBzDF/Dngnqxt7gaeda5vAuqB\nBuA4sNVZfwHYCVx9WSN2+ejiqUwdF2X3yR7++T8Oe/WwIiIlL5/iPx045Fo+7KzLtc2MrG2aMO2g\nTaMb4vCmjqvgiTvnALD58Lkx/62f6mdaysJSFpay8E44j23yrajZHzN2368WeAH4JOYdwEVWrFhB\nY6P54FZdXR0LFy4cfHs38Msebnn/669RcfwAvVMXsPtkN2f3bB1xey2PjeUBfhlPMZdjsZivxlPM\n5Vgs5qvxFHK5ra2NtWvXAtDY2EhLSwuXI5/vhVgCPI7p+QOsAtLAk65tngE2YlpCYCaHbwc6gAjw\nC2A98I3sB8/3u31Gsvp3h/jFzlP89c3T+G+Lpl7WY4mIjAWF+G6fzZiJ3CYgCtwLrMvaZh3wgHN9\nCdCJKfwB4NvADoYo/F5ZdPU4ALYePX+lnkJEpKTkU/yTwEpgA6aIP4+ZuH3IuQC8COzHTAyvAVY4\n628FPgq8F9jiXAbeQXjmxmm1BIAdJ7qJJ9NeP3zBqJ9pKQtLWVjKwjv59PzBtGzWZ61bk7W8coj7\ntVGAD5KNrwzTWF/J2519HDjbx3VTqq/0U4qIjGlj9hO+2a6dVAXAvjH8gS+dw2wpC0tZWMrCOyVT\n/GdPNMV//+meIo9ERMT/Sqb4l8KRv/qZlrKwlIWlLLxTMsXfHvn3ktbf9xURGVHJFP8J1REmVoXp\nSaTpOB8v9nAuifqZlrKwlIWlLLxTMsUfXK2f02O39SMiUgglVfznTTHf8R87/iffIDEmqJ9pKQtL\nWVjKwjslVfwXTzef9P3jEX3SV0RkJCVV/OdfVUN1JMjBzj5OXBh7fX/1My1lYSkLS1l4p6SKfzgY\n4MardfQvIpJLSRV/gJud1s9rh84VeSSjp36mpSwsZWEpC++UXPFf0lhHANh0sIuuvmSxhyMi4ksl\nV/yvqo1y84xxJNIZXtpzptjDGRX1My1lYSkLS1l4p+SKP8AH3jEZgJ/ETvDC6x30jeGveRYRuRJK\nsvgvaayjoTbKqZ4E//fVo3z9lYPFHlJe1M+0lIWlLCxl4Z2SLP6hYICv3TWXTy2dSUU4yMv7zvLy\nvrHVAhIRuZJKsviD6f0vf8dk/seS6QA8v62jyCPKTf1MS1lYysJSFt4p2eI/oHnORMLBAG+d6aM7\nnir2cEREfKHki39FOMicSVVkgJ0nuos9nBGpn2kpC0tZWMrCOyVf/AEWNJgvfNvR4e/iLyJSKGVR\n/K9vqAVgu8+Lv/qZlrKwlIWlLLxTJsXfHPnvOtlNPKVz/kVEyqL4T6qOcM2ESnoTab7224O+/TOP\n6mdaysJSFpay8E6+xX8ZsAvYAzw6zDarndu3AYtc678DdACxSxyjJx674xqqIuac/2+/erSYQxER\nKbp8in8IeAqzA7geuA+Yn7XNcmAOMBd4EHjaddt3nfsW1exJ1XzhfbMIBeBHsRP827YOMj57B6B+\npqUsLGVhKQvv5FP8bwH2AgeABPAccE/WNncDzzrXNwH1wFRn+RXg7OUO1As3zxjP393WCMC3XjvK\nl371Fr/ae4aE5gFEpMzkU/ynA4dcy4eddaPdxhf+Yu4kVr23iYpQgLYDXTy58W3+YcN+zvYmij4X\noH6mpSwsZWEpC++E89gm34oYuMT7sWLFChobzRF5XV0dCxcuHHx7N/DL9nI5AjzzX/6MtgNdfPMn\nG/jNvhRbjp5nSk2Ej151inEV4Sv6/FrOvTzAL+Mp5nIsFvPVeIq5HIvFfDWeQi63tbWxdu1aABob\nG2lpaeFyZBfsoSwBHsf27VcBaeBJ1zbPABsxLSEwk8O3YyZ6AZqAnwMLsx+8tbU1s3jx4tGN2kOH\nu/p4cuPbvHWml3gqw1/On8zDt84s2nhERPLR3t5Oc3NzPjV8SPm0fTZjJnKbgChwL7Aua5t1wAPO\n9SVAJ7bw+9qMukr++Z55PPXBeQQD8P92neJ7fzzG4a6+Yg9NROSKyaf4J4GVwAZgB/A8sBN4yLkA\nvAjsx0wMrwFWuO7/Q+A/gOsw8wIf82LgXmuaUMXyeZNJZ+BftxznkZ+9yYGzvQUdg/qZlrKwlIWl\nLLyTT88fYL1zcVuTtbxymPveN6oRFdEn3j2D6xtqeGnPGbYcPc/n1u/jqx+Yw4y6ymIPTUTEU5fc\nL/JKsXv+Q+lPplm1fi9vdHRTVxlm5btncGtTPeFg0eMSEQEuv+ef75F/WakIB/nystn8r9a3+OOR\n83z51wcIBmBKTZRp46PcPH08t82qZ9r4imIPVUTkkpTFd/tciqpIiC+9fzaP3DqTmXUVpDPQcSHO\n1qMX+PZrR/nrf9vBp9a9ycGz3k0Mq59pKQtLWVjKwjs68h9BOBjgrvmTuWv+ZOKpNCcvxNl/po+2\nA5384WAXO05084mf7ebDNzZw26x6JlZHqI4ECQTUHhIRfyt6lfJjzz8fPfEUq393iF/vu/ibKypC\nAW68ehyzJ1YRDAYIBwNMqYkwoSrCuIoQM+srqYmGijRqESkV6vkXSXU0xKN3XMP7r5vET944waGu\nPs72JulNpHn10DlePXRu2PsO7AyqIkHeMaWa5e+YrPkDESkoFf/LEAgEWDR9HIumjxtcd7YnwR8O\nneNMj/muoHgqw4kLcc71JTnbm+BQVz8nuxOc7E4AsO3YBX66/STvmVXP+f3b+Nz9d1EV0TuDtrY2\nfYOjQ1lYysI7Kv4em1Ad4c55k4a9PZXOcOx8Pxf6U3T2Jfn13jNs3N9J696znNt3hu4N+/jy+2dr\nByAiV5R6/j6wveMCB8728YP245zqSXDtxEo+/Z5GmiZUURHWCVki8qfU8y8BCxpqWdBQy03TxvEP\nG/ax/0wfD//sTUIBmDelhgdunsri6eOLPUwRKSE6rPSRt2Kv8dQH53HnvElcPT5KBthxopvPb9jP\ny/vOkkr76y+PXUk6n9tSFpay8I6O/H2mJhri0+8xf9ugO57iXzYf5Wc7TvGVlw+w+nchrptcTfPc\nCfzn2RMJ6esmROQSFb16qOc/skwmwwuxE6zffZrDXf2D64MBmFgd4eF3z+Q/XVNXxBGKSDGo51/i\nAoEAH7qhgQ/d0MCp7jibD5/nuW0dHD3Xz6nuBI+/tJ/5V9Vw3ZRq/uqdU5g2Tp8XEJHc1PP3kVz9\nzMk1UZbNm8R3PzSfX3zsRv72z6cRCJh5gZ9uP8nfPL+Dh3+2m6/99m1+uPU4W46eJzlG5wnU27WU\nhaUsvKMj/zEoEAgQDQX48I1TaZk7iYOdffxyzxl+s/8su0/2sPtkz+C24ytCLJhay9RxUWoiIaoj\nQZomVvHOqbVU6jRSkbKlnn8J6U2k2N7RzfHzcd4+28eWo+c52Dn0t45WhoMsbaqjYVwFNdEQNdEQ\ntc5l9qQqxlfquEDEz9Tzl0FVkRB/NsN+HiCTyXCoq5/9p3s51R2nJ5HmfH+S7R3d7D3dS+ves0M+\nTiQY4J1Ta2mojRINmy+nq6sMs6Chhuum1Ogdg0gJUPH3Ea+/tyQQCNBYX0lj/Z/+GcpDnX388ch5\nzvcn6Y6nBi9nepLsOtnNlqPnh3zMUADmTK5mQUMN1zfUcE19JdPGVRD1eIeg73CxlIWlLLyj4l+m\nZtZXMnOInQLA6e4Eb57q4XRPgkQqTTKdoeNCnO0d3bx1pndwXuEnb5wETO9wQnWYCVURwsEA9ZVh\nptREqYwEqQwH7b+u6zXREBOrIlSGg0RCAaIh86/+FoJIYRT9f5p6/mNLdzzFzhPd7OjoZtfJbo6e\ni3P8fD9enVRUFQlSHTFzENURs5OoigSJhoJUODuQCvclFKAqEmJcRYjaihCVYbttNBQYvI92KlJq\n1POXgqqJmnkF99xCMp3hTE+Crr4kyXSG0z0JzvQk6Euk6Us6l0Sa3mRqcN2FeIrO3iT9yTTxVJpE\nKkMinaE3kaY3keZ0T8LTMc+aWEllOEgoEKAyHGR8ZZi6yjDjK8NUR8y7jnAwSDgYoCoSpK4yTH1l\nmJpoSO9IpCTlU/yXAd8AQsC3gCeH2GY1cCfQA/wNsGUU9xXHWO1nhoMBrqqNclVt9LIeJ50xxb87\nnuI3v32F629+F93xFH3JNPFkhr5kmv6BS8peH5jI7o6nnHUZ+lNp4sk0/akM3fEUbxzvvuRxBQM4\n7Smzc7joEgr86bpggIjrXYdpd4WIONtHgoHBx4o4y2Z9kHAoQNT1uJFQkC2bfs+tS28dXK4Im/uW\no7H6f8SPchX/EPAU0AwcAV4D1gE7XdssB+YAc4F3AU8DS/K8r7jEYrGyfmEHA4HB005Pvf0mC5a/\nz5PHPdkd53BnP8l0hmQ6Q18yRVdfinN9Sbr6kvQm0ySduY1EKkNPIk2Xc1tPPEUibdaRSHsyntE6\n/korUw/VX7RufEWISChIbUWIKTURJldHqY6651VCTovMvKOJODuT6MA7nMGdkN3pDC6HgoQC+PLd\nTrn/H/FSruJ/C7AXOOAsPwfcw8UF/G7gWef6JqAemArMyuO+4tLV1VXsIfiGl1lMqYkypebS35Uk\nUqZVNbDzSKYzJFOZi5ez1g/cZ+DSn0yTdFpbiVSGZNq2ugaWB3Y+CddjJNIZutJ9TKqOXPS45/pT\nQIrTPQnePjv0ZzkuVzAAoUCAQMDsmIOufwOBAKEAhIKBwfmViDNpHwlevHzx9eDgTiYauniyPxwM\nEAwECAXN84Sc5woFA4SC5vq+o6fYc6rnoh2Z2WE5z+FsK7nlKv7TgUOu5cOYo/tc20wHrs7jviK+\nZwpX8T7b8MS+KTz2kXcOLqfSGc71J0mkMpzvT3KyO8Gp7gS9idTg/MrATieeSg/ukOKuncrgjsa1\nPLhNKk0qA+mMacUZ/viakCO7T/P6T3ePuE0wgKv9FiQUxLy7cbXdwq5WW3UkSFU0RFXYuR4xJxlU\nOycbVDvLV+o1cFVNhPqqyBV57JHkKv75/sa1q/XAwYMHiz0E31AWVnYWoWCACU6xuKo2yuzh/2ro\nJUtnMqb4pzOkMf9mMDueDHZ9MmXnVwZ2JPHUwDuYgevmtsHrqYyd5B+4ns6Qci7pDKQyA9czpNJm\nPKlMhtO9p5g9qcr1Lsq+g0o6z5fOQDxlnq9YrbrR+NTSmSx/x+SCP2+uor0EeBwzcQuwCkhz8cTt\nM8BGTFsIZl+iAAAC80lEQVQHYBdwO6btk+u+fP/73987bdq02ZcyeBGRcnXs2LF9999//5wr9fhh\nYB/QBESBrcD8rG2WAy8615cAfxjFfUVExKfuBHZjJm9XOeseci4DnnJu3wYsznFfEREREREpN8sw\ncwR7gEeLPJZiOAC8jvlQ3KvOuonAS8CbwC8xp86Wou8AHUDMtW6kn30V5nWyC2gp0BgLZagsHsec\nIbfFudzpuq1Us5gJvAxsB94AHnHWl+PrYrgsHqcEXhchTDuoCYhQnnMCb2Fe2G5fBT7rXH8UeKKg\nIyqc9wCLuLjgDfezX495fUQwr5e9lNZfoRsqiy8CfzfEtqWcxVTgJud6LaZlPJ/yfF0Ml4Vnr4ti\nBuX+AFkC+yGwcpN9xpX7Q3PPAh8s7HAK5hUg+w8KDPez3wP8EPM6OYB53dxy5YdYMENlAUOfjVfK\nWRzHFDCAC5gPhE6nPF8Xw2UBHr0uiln8h/twWDnJAK3AZuDjzroGTAsA59+GIoyrWIb72a/GvD4G\nlMtr5WHMSRTfxrY6yiWLJsy7oU3oddGEyWLgTEpPXhfFLP7++Mhgcd2K+aXeCXwC8/bfLUP55pTr\nZy/1XJ7GfFbmJuAY8LURti21LGqBHwOfBLL/qlC5vS5qgRcwWVzAw9dFMYv/EcykxoCZXLznKgfH\nnH9PAv+OeZvWgen3AUwDThRhXMUy3M+e/VqZ4awrZSewhe5b2LfwpZ5FBFP4vw/81FlXrq+LgSz+\nFZtFSbwuyv1DYNXAOOd6DfA7zAz9V7FnPj1G6U74gvndZ0/4DvWzD0xmRTFHPfsova8UaeLiLKa5\nrn8aWOtcL+UsAsD3gK9nrS/H18VwWZTM66KcPwQ2C/PL2oo5lWvg55+ImQco9VM9fwgcBeKYuZ+P\nMfLP/jnM62QX8P6CjvTKy87ibzH/8V/H9HZ/ysVzP6WaxVLMV8BsxZ7KuIzyfF0MlcWdlOfrQkRE\nRERERERERERERERERERERERERERERESk9Px/BcZXa+YXVXoAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11b1e4d10>"
       ]
      }
     ],
     "prompt_number": 671
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 672
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 673
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 674,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 674
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 675
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 676
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 677
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from gradient_boost_loss import NAUC \n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn.ensemble import GradientBoostingClassifier \n",
      "            est = GradientBoostingClassifier()\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "#             est.loss__ = NAUC(2)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 678
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'n_estimators': 1000,\n",
      "    'pratio': 1,\n",
      "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.)),\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'max_features': hp.quniform( 'max_features', 10, 30, 1),\n",
      "    'max_depth': hp.quniform( 'max_depth', 2, 18, 1),\n",
      "    'min_samples_leaf': hp.quniform( 'min_samples_leaf', 2, 30, 1),\n",
      "#     'subsample': hp.uniform( 'subsample', 0.2, 0.9),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 679
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 680
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[stderr:5] \n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:397: RuntimeWarning: overflow encountered in double_scalars\n",
        "  tree.value[leaf, 0, 0] = numerator / denominator\n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:371: RuntimeWarning: invalid value encountered in multiply\n",
        "  return -2.0 * np.mean((y * pred) - np.logaddexp(0.0, pred))\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:102]: \u001b[0m\n",
        "{'learning_rate': 0.022826489171967838,\n",
        " 'max_depth': 10.0,\n",
        " 'max_features': 23.0,\n",
        " 'min_samples_leaf': 19.0,\n",
        " 'nf': 179.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:102]: \u001b[0m\n",
        "{'learning_rate': 0.7314357184140008,\n",
        " 'max_depth': 9.0,\n",
        " 'max_features': 22.0,\n",
        " 'min_samples_leaf': 7.0,\n",
        " 'nf': 65.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:102]: \u001b[0m\n",
        "{'learning_rate': 0.05334526725871157,\n",
        " 'max_depth': 3.0,\n",
        " 'max_features': 16.0,\n",
        " 'min_samples_leaf': 16.0,\n",
        " 'nf': 174.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:102]: \u001b[0m\n",
        "{'learning_rate': 0.024494974453583774,\n",
        " 'max_depth': 4.0,\n",
        " 'max_features': 23.0,\n",
        " 'min_samples_leaf': 30.0,\n",
        " 'nf': 75.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:102]: \u001b[0m\n",
        "{'learning_rate': 0.016763857399279505,\n",
        " 'max_depth': 4.0,\n",
        " 'max_features': 28.0,\n",
        " 'min_samples_leaf': 5.0,\n",
        " 'nf': 94.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:102]: \u001b[0m\n",
        "{'learning_rate': 0.7140129597488567,\n",
        " 'max_depth': 2.0,\n",
        " 'max_features': 21.0,\n",
        " 'min_samples_leaf': 10.0,\n",
        " 'nf': 145.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:102]: \u001b[0m\n",
        "{'learning_rate': 0.05561432240316577,\n",
        " 'max_depth': 11.0,\n",
        " 'max_features': 13.0,\n",
        " 'min_samples_leaf': 14.0,\n",
        " 'nf': 55.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:102]: \u001b[0m\n",
        "{'learning_rate': 0.3030161471276105,\n",
        " 'max_depth': 2.0,\n",
        " 'max_features': 14.0,\n",
        " 'min_samples_leaf': 12.0,\n",
        " 'nf': 20.0}"
       ]
      }
     ],
     "prompt_number": 681
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.978520793951 1.0 {'n_estimators': 1000, 'pratio': 1, 'max_features': 16.0, 'learning_rate': 0.05334526725871157, 'max_depth': 3.0, 'nf': 174.0, 'min_samples_leaf': 16.0}\r\n",
        "0.974787334594 1.0 {'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'learning_rate': 0.052284857509877845, 'max_depth': 2.0, 'nf': 222.0, 'min_samples_leaf': 3.0}\r\n",
        "0.973393194707 1.0 {'n_estimators': 1000, 'pratio': 1, 'max_features': 27.0, 'learning_rate': 0.07488486346245497, 'max_depth': 2.0, 'nf': 217.0, 'min_samples_leaf': 26.0}\r\n",
        "0.972188090737 1.0 {'n_estimators': 1000, 'pratio': 1, 'max_features': 29.0, 'learning_rate': 0.11225725099695992, 'max_depth': 2.0, 'nf': 222.0, 'min_samples_leaf': 26.0}\r\n",
        "0.971975425331 1.0 {'n_estimators': 1000, 'pratio': 1, 'max_features': 25.0, 'learning_rate': 0.06734604473269949, 'max_depth': 3.0, 'nf': 217.0, 'min_samples_leaf': 22.0}\r\n"
       ]
      }
     ],
     "prompt_number": 682
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    args = eval(''.join(l[2:]))\n",
      "    hyeropt_results.append((validate_score, train_score, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 683,
       "text": [
        "763"
       ]
      }
     ],
     "prompt_number": 683
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 684,
       "text": [
        "(502, 240)"
       ]
      }
     ],
     "prompt_number": 684
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: /tmp/Xt.mmap: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 685
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 686
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 687
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    est = GradientBoostingClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return roc_auc_score(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 688
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 689
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for res in hyeropt_results:\n",
      "    args = res[2]\n",
      "    print args\n",
      "    args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'learning_rate': 0.05334526725871157, 'nf': 174.0, 'min_samples_leaf': 16.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 16.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.052284857509877845, 'nf': 222.0, 'min_samples_leaf': 3.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.07488486346245497, 'nf': 217.0, 'min_samples_leaf': 26.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 27.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.11225725099695992, 'nf': 222.0, 'min_samples_leaf': 26.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 29.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.06734604473269949, 'nf': 217.0, 'min_samples_leaf': 22.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 25.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.11091771632280131, 'nf': 197.0, 'min_samples_leaf': 27.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 28.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.038724644390612684, 'nf': 210.0, 'min_samples_leaf': 21.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 24.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.06511729538365887, 'nf': 178.0, 'min_samples_leaf': 18.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 21.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.183825726273952, 'nf': 157.0, 'min_samples_leaf': 29.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 15.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.13187138366127654, 'nf': 163.0, 'min_samples_leaf': 19.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 19.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.16127506098947533, 'nf': 194.0, 'min_samples_leaf': 26.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 27.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.040411449820212476, 'nf': 236.0, 'min_samples_leaf': 20.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 29.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.09040914680184965, 'nf': 232.0, 'min_samples_leaf': 26.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 28.0, 'max_depth': 2.0}\n",
        "{'learning_rate': 0.08522951820841972, 'nf': 181.0, 'min_samples_leaf': 13.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 26.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.030050290129241226, 'nf': 209.0, 'min_samples_leaf': 9.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 13.0, 'max_depth': 3.0}\n",
        "{'learning_rate': 0.09329387466127517, 'nf': 201.0, 'min_samples_leaf': 13.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 22.0, 'max_depth': 3.0}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 690,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 690
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 691
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.933754725898\n",
        "0.681498109641\n",
        "0.806923440454"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.800543478261\n",
        "0.961153119093\n",
        "0.804619565217\n",
        "0.709463610586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.898239603025\n",
        "0.846065689981\n",
        "0.904005198488\n",
        "0.621030245747\n",
        "0.740879017013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.756557183365\n",
        "0.657974952741\n",
        "0.58034026465\n",
        "0.645782136106\n",
        "0.668643667297\n",
        "0.816020793951\n",
        "0.664933837429"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.874279300567\n",
        "0.689142249527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.831970699433\n",
        "0.583069470699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.881214555766\n",
        "0.788350661626\n",
        "0.742556710775\n",
        "0.487689035917\n",
        "0.868998109641"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.766564272212\n",
        "0.69734168242\n",
        "0.808754725898\n",
        "0.883211247637\n",
        "0.58540879017\n",
        "0.770061436673\n",
        "0.726063327032"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.864945652174\n",
        "0.650224480151\n",
        "0.879595935728\n",
        "0.709652646503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.933270321361\n",
        "0.546042060491\n",
        "0.738232514178\n",
        "0.884735349716\n",
        "0.716587901701"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.884073724008\n",
        "0.892781190926\n",
        "0.824362003781\n",
        "0.937062854442\n",
        "0.970061436673\n",
        "0.823558601134\n",
        "0.941434310019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.804217863894\n",
        "0.725827032136\n",
        "0.901618620038\n",
        "0.662570888469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.867922967864\n",
        "0.794210775047\n",
        "0.660479678639\n",
        "0.686696597353\n",
        "0.614413988658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.670557655955\n",
        "0.651677693762\n",
        "0.698428638941\n",
        "0.588492438563\n",
        "0.912157372401\n",
        "0.821526465028\n",
        "0.634617202268"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.893927221172\n",
        "0.791469754253\n",
        "0.966209829868\n",
        "0.843903591682"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.738764177694\n",
        "0.502622873346\n",
        "0.845675803403\n",
        "0.722566162571\n",
        "0.880210302457"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.750933364839\n",
        "0.652292060491\n",
        "0.96963610586\n",
        "0.590536389414\n",
        "0.804879489603\n",
        "0.716268903592\n",
        "0.914177693762"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.951110586011\n",
        "0.84109168242\n",
        "0.927646502836\n",
        "0.959286389414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.841989603025\n",
        "0.819116257089\n",
        "0.819966918715\n",
        "0.879418714556\n",
        "0.716623345936"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.430281190926\n",
        "0.638953213611\n",
        "0.680316635161\n",
        "0.654040642722\n",
        "0.769104442344\n",
        "0.9654536862\n",
        "0.715359168242"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.846172022684\n",
        "0.70177221172\n",
        "0.655470226843\n",
        "0.862925330813"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.612712665406\n",
        "0.699810964083\n",
        "0.676689508507\n",
        "0.602835538752\n",
        "0.837381852552"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.937807183365\n",
        "0.711838374291\n",
        "0.86190926276\n",
        "0.863586956522\n",
        "0.569470699433\n",
        "0.692509451796\n",
        "0.919517958412"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.86099952741\n",
        "0.907655954631"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.660775047259\n",
        "0.628449905482"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.647518903592\n",
        "0.671301984877\n",
        "0.829879489603\n",
        "0.852032136106\n",
        "0.581911625709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.797093572779\n",
        "0.872956049149\n",
        "0.952670132325\n",
        "0.639780245747\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 692
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 693
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_count == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 694,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 694
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 695,
       "text": [
        "0.73771701388888611"
       ]
      }
     ],
     "prompt_number": 695
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 696
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140926-GBC-combine"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}