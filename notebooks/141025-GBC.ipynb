{
 "metadata": {
  "name": "",
  "signature": "sha256:94d4464999b13249e1a6e641fe21c03ce1ea79b8f011556f39931e9b53030491"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Dog_1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8.5_medianwindow1-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LOCAL_HOSTNAME=!hostname\n",
      "if LOCAL_HOSTNAME[0].startswith('ip-'):\n",
      "    !aws s3 cp s3://udikaggle/sezure/{FEATURES}.tgz data-cache/\n",
      "    !tar xfz data-cache/{FEATURES}.tgz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "(184, 240)"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 265,
       "text": [
        "(3680, 240)"
       ]
      }
     ],
     "prompt_number": 265
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)\n",
      "Ntrainns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dog_1 0.047619047619 184 3680\n",
        "Dog_1 0.047619047619 4 80\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 268,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 271,
       "text": [
        "(3864, 240)"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 272,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 273,
       "text": [
        "0.95238095238095233"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "[<matplotlib.lines.Line2D at 0x116955d90>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD+tzr1zGejFFAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11c5e04d0>"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/X.mmap\n",
      "mmX = np.memmap('../data-cache/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 277,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 278
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('../data-cache/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 280
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from gradient_boost_loss import NAUC\n",
      "import os\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn.ensemble import GradientBoostingClassifier \n",
      "            est = GradientBoostingClassifier()\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "#             est.loss__ = NAUC(2)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, os.getpid(), args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'pid':os.getpid(),\n",
      "                    'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 100)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 281
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'n_estimators': 1000,\n",
      "    'pratio': 1,\n",
      "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(1.)),\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'max_features': hp.quniform( 'max_features', 10, 30, 1),\n",
      "    'max_depth': hp.quniform( 'max_depth', 2, 18, 1),\n",
      "    'min_samples_leaf': hp.quniform( 'min_samples_leaf', 2, 30, 1),\n",
      "#     'subsample': hp.uniform( 'subsample', 0.2, 0.9),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[stderr:3] \n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:375: RuntimeWarning: overflow encountered in exp\n",
        "  return y - 1.0 / (1.0 + np.exp(-pred.ravel()))\n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:1136: RuntimeWarning: overflow encountered in exp\n",
        "  proba[:, 1] = 1.0 / (1.0 + np.exp(-score.ravel()))\n",
        "[stderr:6] \n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:397: RuntimeWarning: overflow encountered in double_scalars\n",
        "  tree.value[leaf, 0, 0] = numerator / denominator\n",
        "/Users/udi/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:371: RuntimeWarning: invalid value encountered in multiply\n",
        "  return -2.0 * np.mean((y * pred) - np.logaddexp(0.0, pred))\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:11]: \u001b[0m\n",
        "{'learning_rate': 0.0010498758969172122,\n",
        " 'max_depth': 11.0,\n",
        " 'max_features': 10.0,\n",
        " 'min_samples_leaf': 15.0,\n",
        " 'nf': 204.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:11]: \u001b[0m\n",
        "{'learning_rate': 0.0031983913366845943,\n",
        " 'max_depth': 5.0,\n",
        " 'max_features': 11.0,\n",
        " 'min_samples_leaf': 24.0,\n",
        " 'nf': 61.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:11]: \u001b[0m\n",
        "{'learning_rate': 0.01283444559626582,\n",
        " 'max_depth': 10.0,\n",
        " 'max_features': 28.0,\n",
        " 'min_samples_leaf': 25.0,\n",
        " 'nf': 33.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:11]: \u001b[0m\n",
        "{'learning_rate': 0.04739289686825279,\n",
        " 'max_depth': 4.0,\n",
        " 'max_features': 21.0,\n",
        " 'min_samples_leaf': 7.0,\n",
        " 'nf': 25.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:11]: \u001b[0m\n",
        "{'learning_rate': 0.5619827593178974,\n",
        " 'max_depth': 3.0,\n",
        " 'max_features': 14.0,\n",
        " 'min_samples_leaf': 20.0,\n",
        " 'nf': 145.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:11]: \u001b[0m\n",
        "{'learning_rate': 0.784126081590437,\n",
        " 'max_depth': 5.0,\n",
        " 'max_features': 22.0,\n",
        " 'min_samples_leaf': 9.0,\n",
        " 'nf': 26.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:11]: \u001b[0m\n",
        "{'learning_rate': 0.09017661551377924,\n",
        " 'max_depth': 8.0,\n",
        " 'max_features': 14.0,\n",
        " 'min_samples_leaf': 7.0,\n",
        " 'nf': 43.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:11]: \u001b[0m\n",
        "{'learning_rate': 0.009973824317616536,\n",
        " 'max_depth': 8.0,\n",
        " 'max_features': 15.0,\n",
        " 'min_samples_leaf': 21.0,\n",
        " 'nf': 24.0}"
       ]
      }
     ],
     "prompt_number": 284
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.952811909263 0.999981621508 85168 {'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'learning_rate': 0.0031983913366845943, 'max_depth': 5.0, 'nf': 61.0, 'min_samples_leaf': 24.0}\r\n",
        "0.940288279773 1.0 85168 {'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'learning_rate': 0.00343375365403269, 'max_depth': 16.0, 'nf': 66.0, 'min_samples_leaf': 23.0}\r\n",
        "0.940028355388 1.0 85168 {'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'learning_rate': 0.003509339065116737, 'max_depth': 10.0, 'nf': 58.0, 'min_samples_leaf': 26.0}\r\n",
        "0.939839319471 1.0 85168 {'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'learning_rate': 0.002778208474186891, 'max_depth': 10.0, 'nf': 58.0, 'min_samples_leaf': 23.0}\r\n",
        "0.93693289225 1.0 85168 {'n_estimators': 1000, 'pratio': 1, 'max_features': 19.0, 'learning_rate': 0.0015127996448379177, 'max_depth': 10.0, 'nf': 66.0, 'min_samples_leaf': 22.0}\r\n"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = float(l[0])\n",
      "    train_score = float(l[1])\n",
      "    pid = int(l[2])\n",
      "    args = eval(''.join(l[3:]))\n",
      "    hyeropt_results.append((validate_score, train_score, pid, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 286,
       "text": [
        "750"
       ]
      }
     ],
     "prompt_number": 286
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 287,
       "text": [
        "(502, 240)"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: /tmp/Xt.mmap: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('../data-cache/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 290
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    est = GradientBoostingClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return roc_auc_score(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "pid2args_list = defaultdict(list)\n",
      "for res in hyeropt_results:\n",
      "    validation_score = res[0]\n",
      "    test_score = res[1]\n",
      "    pid = res[2]\n",
      "    args = res[3]\n",
      "    pid2args_list[pid].append((validation_score, args))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for v in pid2args_list.values():\n",
      "    print v[1]\n",
      "    for vv in v[:4]:\n",
      "        args_list.append(vv[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.883884688091, {'learning_rate': 0.0010136908049956917, 'nf': 182.0, 'min_samples_leaf': 5.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'max_depth': 7.0})\n",
        "(0.940288279773, {'learning_rate': 0.00343375365403269, 'nf': 66.0, 'min_samples_leaf': 23.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'max_depth': 16.0})\n",
        "(0.801358695652, {'learning_rate': 0.1750583614936522, 'nf': 34.0, 'min_samples_leaf': 6.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 12.0, 'max_depth': 4.0})\n",
        "(0.753213610586, {'learning_rate': 0.0741535672683746, 'nf': 23.0, 'min_samples_leaf': 23.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'max_depth': 7.0})\n",
        "(0.673806710775, {'learning_rate': 0.9181601344715175, 'nf': 69.0, 'min_samples_leaf': 11.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 11.0, 'max_depth': 11.0})\n",
        "(0.906379962193, {'learning_rate': 0.026892507420351906, 'nf': 165.0, 'min_samples_leaf': 14.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 23.0, 'max_depth': 4.0})\n",
        "(0.805860113422, {'learning_rate': 0.2597263691779113, 'nf': 68.0, 'min_samples_leaf': 28.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 22.0, 'max_depth': 4.0})\n",
        "(0.735798676749, {'learning_rate': 0.03724239056454134, 'nf': 32.0, 'min_samples_leaf': 10.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 20.0, 'max_depth': 14.0})\n"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "[{'learning_rate': 0.0010498758969172122,\n",
        "  'max_depth': 11.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 15.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 204.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0010136908049956917,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 5.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 182.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0010055627809472077,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 12.0,\n",
        "  'min_samples_leaf': 7.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 212.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0010027447303887003,\n",
        "  'max_depth': 18.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 12.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 216.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0031983913366845943,\n",
        "  'max_depth': 5.0,\n",
        "  'max_features': 11.0,\n",
        "  'min_samples_leaf': 24.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 61.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.00343375365403269,\n",
        "  'max_depth': 16.0,\n",
        "  'max_features': 11.0,\n",
        "  'min_samples_leaf': 23.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 66.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.003509339065116737,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 26.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 58.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.002778208474186891,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 23.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 58.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.784126081590437,\n",
        "  'max_depth': 5.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 9.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 26.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.1750583614936522,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 12.0,\n",
        "  'min_samples_leaf': 6.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 34.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.7180933422404562,\n",
        "  'max_depth': 5.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 5.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 26.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.06587298997783339,\n",
        "  'max_depth': 2.0,\n",
        "  'max_features': 25.0,\n",
        "  'min_samples_leaf': 7.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 84.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.009973824317616536,\n",
        "  'max_depth': 8.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 21.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 24.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0741535672683746,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 23.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 23.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.024577806863275486,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 22.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 25.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.005323705105407962,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 6.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 45.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.09017661551377924,\n",
        "  'max_depth': 8.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 7.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 43.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.9181601344715175,\n",
        "  'max_depth': 11.0,\n",
        "  'max_features': 11.0,\n",
        "  'min_samples_leaf': 11.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 69.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.005323705105407962,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 6.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 45.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.44574987519394016,\n",
        "  'max_depth': 11.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 15.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 30.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.5619827593178974,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 145.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.026892507420351906,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 23.0,\n",
        "  'min_samples_leaf': 14.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 165.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.06157781859572993,\n",
        "  'max_depth': 2.0,\n",
        "  'max_features': 16.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 150.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.11807577956543125,\n",
        "  'max_depth': 2.0,\n",
        "  'max_features': 29.0,\n",
        "  'min_samples_leaf': 16.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 226.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.04739289686825279,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 21.0,\n",
        "  'min_samples_leaf': 7.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 25.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.2597263691779113,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 28.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 68.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.1750583614936522,\n",
        "  'max_depth': 4.0,\n",
        "  'max_features': 12.0,\n",
        "  'min_samples_leaf': 6.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 34.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.1430414457196126,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 28.0,\n",
        "  'min_samples_leaf': 15.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 28.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.01283444559626582,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 28.0,\n",
        "  'min_samples_leaf': 25.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 33.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.03724239056454134,\n",
        "  'max_depth': 14.0,\n",
        "  'max_features': 20.0,\n",
        "  'min_samples_leaf': 10.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 32.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.020254421213450544,\n",
        "  'max_depth': 16.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 17.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 23.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.06837368966399225,\n",
        "  'max_depth': 8.0,\n",
        "  'max_features': 25.0,\n",
        "  'min_samples_leaf': 19.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 28.0,\n",
        "  'pratio': 1}]"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.852457466919\n",
        "0.519541587902\n",
        "0.883459357278\n",
        "0.841304347826"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.925354442344\n",
        "0.889792060491\n",
        "0.895510396975\n",
        "0.584239130435\n",
        "0.557360586011\n",
        "0.736791115312\n",
        "0.693986294896\n",
        "0.867438563327\n",
        "0.905801039698"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.819128071834\n",
        "0.792391304348\n",
        "0.712169187146\n",
        "0.845888468809\n",
        "0.554465973535\n",
        "0.599338374291\n",
        "0.863055293006\n",
        "0.751417769376\n",
        "0.944447069943"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.698086011342\n",
        "0.799137523629\n",
        "0.890146502836\n",
        "0.673877599244\n",
        "0.915619092628\n",
        "0.854737712665\n",
        "0.88809073724"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.889024102079\n",
        "0.653733459357\n",
        "0.945191398866\n",
        "0.935656899811\n",
        "0.518336483932\n",
        "0.491753308129\n",
        "0.855907372401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.90775047259\n",
        "0.935278827977\n",
        "0.88811436673\n",
        "0.629312381853\n",
        "0.300141776938"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.80979442344\n",
        "0.791694234405\n",
        "0.898322306238\n",
        "0.759109168242"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.833742911153\n",
        "0.790879017013\n",
        "0.867084120983\n",
        "0.634404536862\n",
        "0.55652173913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.689224952741\n",
        "0.757667769376\n",
        "0.638019848771\n",
        "0.87258979206\n",
        "0.867367674858\n",
        "0.673168714556\n",
        "0.915867202268\n",
        "0.906450850662\n",
        "0.755505671078\n",
        "0.767202268431\n",
        "0.748275047259"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.825330812854\n",
        "0.450968809074\n",
        "0.766670604915\n",
        "0.785656899811\n",
        "0.836649338374\n",
        "0.555151228733\n",
        "0.434310018904\n",
        "0.896810018904\n",
        "0.665004725898\n",
        "0.550330812854\n",
        "0.552008506616\n",
        "0.32738657845"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.73095463138\n",
        "0.584239130435"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.767757561437\n",
        "0.747258979206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.692474007561\n",
        "0.745061436673\n",
        "0.728260869565\n",
        "0.617946597353\n",
        "0.475543478261"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.717556710775\n",
        "0.75418241966\n",
        "0.682691398866\n",
        "0.889555765595\n",
        "0.88659026465\n",
        "0.82854442344\n",
        "0.871231096408\n",
        "0.902611058601\n",
        "0.743123818526\n",
        "0.651039697543\n",
        "0.756013705104"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.625649810964\n",
        "0.716965973535\n",
        "0.583872873346\n",
        "0.360231568998\n",
        "0.455245746692\n",
        "0.358719281664\n",
        "0.495864839319\n",
        "0.887192816635\n",
        "0.874858223062\n",
        "0.926075141777\n",
        "0.89643194707\n",
        "0.511413043478\n",
        "0.889673913043\n",
        "0.423688563327\n",
        "0.897731568998\n",
        "0.838586956522"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.875378071834\n",
        "0.783683837429\n",
        "0.709475425331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.633672022684\n",
        "0.603804347826"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.557017958412\n",
        "0.706935255198\n",
        "0.888693289225\n",
        "0.93986294896\n",
        "0.92025047259\n",
        "0.907963137996\n",
        "0.774137523629\n",
        "0.57234168242\n",
        "0.618371928166\n",
        "0.63063563327\n",
        "0.555730151229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.801630434783\n",
        "0.646892722117\n",
        "0.79047731569\n",
        "0.91429584121\n",
        "0.408861058601\n",
        "0.918383742911\n",
        "0.429194234405"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.673416824197\n",
        "0.640406427221\n",
        "0.89286389414\n",
        "0.906190926276\n",
        "0.457785916824\n",
        "0.756356332703\n",
        "0.750094517958\n",
        "0.818100189036\n",
        "0.861200378072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.84731805293\n",
        "0.928071833648\n",
        "0.879631379962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.878060018904\n",
        "0.534239130435"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.733648393195\n",
        "0.699834593573\n",
        "0.687925330813\n",
        "0.677575614367\n",
        "0.926843100189\n",
        "0.63331758034\n",
        "0.740914461248\n",
        "0.685491493384\n",
        "0.841398865784\n",
        "0.776335066163\n",
        "0.848582230624"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.864201323251\n",
        "0.709948015123\n",
        "0.786543005671\n",
        "0.819470699433\n",
        "0.538835066163\n",
        "0.906143667297\n",
        "0.86963610586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.947684310019\n",
        "0.888327032136"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.465571833648\n",
        "0.901299621928\n",
        "0.412393667297\n",
        "0.891186200378\n",
        "0.44402173913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.718442816635\n",
        "0.837736294896"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.815087429112\n",
        "0.746597353497"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.751323251418"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.831734404537\n",
        "0.423913043478"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.706120037807\n",
        "0.743466446125\n",
        "0.659936200378\n",
        "0.833459357278\n",
        "0.849373818526\n",
        "0.843797258979\n",
        "0.870215028355\n",
        "0.713244328922\n",
        "0.847885160681\n",
        "0.861755671078\n",
        "0.73065926276"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.912878071834\n",
        "0.77440926276\n",
        "0.865902646503\n",
        "0.421148393195\n",
        "0.879985822306\n",
        "0.905836483932\n",
        "0.890689981096"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.921502835539\n",
        "0.627646502836\n",
        "0.791753308129\n",
        "0.639933837429\n",
        "0.494706994329"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.782254253308\n",
        "0.516824196597\n",
        "0.931084593573\n",
        "0.83513705104"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.812889886578\n",
        "0.739673913043\n",
        "0.913397920605"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.673475897921\n",
        "0.4125"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.645037807183\n",
        "0.661720226843\n",
        "0.855564744802\n",
        "0.838256143667\n",
        "0.856309073724\n",
        "0.629395085066\n",
        "0.734120982987\n",
        "0.868052930057\n",
        "0.653142722117\n",
        "0.883353024575\n",
        "0.775437145558"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.89820415879\n",
        "0.925011814745\n",
        "0.759652646503\n",
        "0.918289224953\n",
        "0.925897920605\n",
        "0.504702268431\n",
        "0.782632325142"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.931450850662\n",
        "0.813279773157\n",
        "0.856970699433\n",
        "0.967958412098\n",
        "0.510562381853\n",
        "0.74734168242\n",
        "0.80088610586\n",
        "0.854643194707\n",
        "0.759924385633"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.688008034026\n",
        "0.868797258979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.82320415879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.853237240076\n",
        "0.645888468809"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.602055765595\n",
        "0.909664461248\n",
        "0.788244328922\n",
        "0.865040170132\n",
        "0.834711720227\n",
        "0.973393194707\n",
        "0.798735822306\n",
        "0.491434310019\n",
        "0.912712665406\n",
        "0.895793950851\n",
        "0.908813799622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.894376181474\n",
        "0.813799621928\n",
        "0.770392249527\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_count == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 299,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 300,
       "text": [
        "0.70815972222222223"
       ]
      }
     ],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140926-GBC-combine"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}