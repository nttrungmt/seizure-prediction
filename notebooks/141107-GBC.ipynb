{
 "metadata": {
  "name": "",
  "signature": "sha256:2b71390e18766eaa2f3ed63db32a560b339b2245552e8b520652d92f8c53e5ea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Patient_2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70'\n",
      "FEATURES1 = 'gen-8_maxdiff-60'\n",
      "\n",
      "nbands = 0\n",
      "nwindows = 0\n",
      "for p in FEATURES.split('-'):\n",
      "    if p[0] == 'b':\n",
      "        nbands += 1\n",
      "    elif p[0] == 'w':\n",
      "        nwindows = int(p[1:])\n",
      "\n",
      "nbands -= 1\n",
      "nbands, nwindows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "(5, 60)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "\n",
      "def read_data(target, data_type, features=FEATURES):\n",
      "    fname = 'data_%s_%s_%s'%(data_type,target,features)\n",
      "    print fname\n",
      "    return cached_data_loader.load(fname,None)\n",
      "\n",
      "def process(X, X1, percentile=[0.05,0.95], nunits=2, mask_level=7000):\n",
      "    N, Nf = X.shape\n",
      "    print '# samples',N,'# power points', Nf\n",
      "    nchannels = Nf / (nbands*nwindows)\n",
      "    print '# channels', nchannels\n",
      "\n",
      "    fix = defaultdict(int)\n",
      "    newX = []\n",
      "    for i in range(N):\n",
      "        nw = nwindows//nunits\n",
      "        windows = X[i,:].reshape((nunits,nw,-1))\n",
      "        mask = X1[i,:].reshape((nunits,nw,-1)) # max value for each channel\n",
      "        for j in range(nunits):\n",
      "            for k in range(nchannels):\n",
      "                m = mask[j,:,k] > mask_level # find large windows\n",
      "                if np.any(m):\n",
      "#                     print 'FIX', sum(m)\n",
      "                    fix[sum(m)] += 1\n",
      "                    if not np.all(m): # make sure we had at least one good window so we can re use its values\n",
      "                        # replace the bands of a large windows with the mean of the bands in all other windows\n",
      "                        windows[j,m,k*nbands:(k+1)*nbands] = np.mean(windows[j,~m,k*nbands:(k+1)*nbands], axis=0)\n",
      "        sorted_windows = np.sort(windows, axis=1)\n",
      "        features = np.concatenate([sorted_windows[:,int(p*nw),:] for p in percentile], axis=-1)\n",
      "        newX.append(features.ravel())\n",
      "    newX = np.array(newX)\n",
      "    print sorted(fix.items())\n",
      "    return newX\n",
      "\n",
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments\n",
      "\n",
      "def getdata():\n",
      "    pdata = read_data(target, 'preictal') # positive examples\n",
      "    Np, _ = pdata.X.shape\n",
      "    print 'Positive examples',Np,\n",
      "    psegments = getsegments(pdata)\n",
      "    Nps = len(psegments)\n",
      "    print 'sequences:',Nps\n",
      "    \n",
      "\n",
      "    ndata = read_data(target, 'interictal') # negative examples\n",
      "    Nn, _ = ndata.X.shape\n",
      "    print 'Negative',Nn,\n",
      "    nsegments = getsegments(ndata)\n",
      "    Nns = len(nsegments)\n",
      "    print 'sequences:',Nns\n",
      "\n",
      "    X = np.concatenate((pdata.X, ndata.X))\n",
      "    print 'p-ratio',float(Np)/(Np+Nn), 'sequences p-ratio:',float(Nps)/(Nps+Nns)\n",
      "    nsegments = [[s+Np for s in ns] for ns in nsegments]\n",
      "    latencies = np.concatenate((pdata.latencies,ndata.latencies))\n",
      "\n",
      "    pdata1 = read_data(target, 'preictal', FEATURES1) # positive examples\n",
      "    ndata1 = read_data(target, 'interictal', FEATURES1) # negative examples\n",
      "    X1 = np.concatenate((pdata1.X, ndata1.X))\n",
      "\n",
      "    print 'Training:'\n",
      "    X = process(X, X1)\n",
      "    \n",
      "    \n",
      "    y = np.zeros(X.shape[0])\n",
      "    y[:Np] = 1\n",
      "    \n",
      "    print 'Test:'\n",
      "    tdata = read_data(target, 'test') # test examples\n",
      "    tdata1 = read_data(target, 'test', FEATURES1) # test examples\n",
      "    Xt = process(tdata.X, tdata1.X)\n",
      "    \n",
      "    return X,y,Xt,psegments,nsegments,latencies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y,Xt,psegments,nsegments,latencies = getdata()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_preictal_Patient_2_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "Positive examples 138 sequences: 3\n",
        "data_interictal_Patient_2_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "Negative 42 sequences: 7\n",
        "p-ratio 0.766666666667 sequences p-ratio: 0.3\n",
        "data_preictal_Patient_2_gen-8_maxdiff-60\n",
        "data_interictal_Patient_2_gen-8_maxdiff-60\n",
        "Training:\n",
        "# samples 180 # power points 7200\n",
        "# channels 24\n",
        "[(1, 189)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test:\n",
        "data_test_Patient_2_gen-8_allbands2-usf-w60-b0.2-b4-b8-b12-b30-b70\n",
        "data_test_Patient_2_gen-8_maxdiff-60\n",
        "# samples 150 # power points 7200\n",
        "# channels 24\n",
        "[(1, 3), (2, 1), (3, 5), (4, 2), (5, 4), (6, 4), (7, 6), (8, 9), (9, 4), (10, 5), (12, 3), (13, 3), (14, 12), (16, 4)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "(180, 480)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.8833333333333333"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[<matplotlib.lines.Line2D at 0x114791f10>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x116b7cf10>"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/X.mmap\n",
      "mmX = np.memmap('/tmp/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X[:,pn_importance_order]\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('/tmp/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N, pratio=1):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = list(itertools.chain(*ns)) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = s + n\n",
      "    random.shuffle(sample_validate)\n",
      "    \n",
      "    \n",
      "    all_p = list(itertools.chain(*psegments))\n",
      "    all_n = list(itertools.chain(*nsegments))\n",
      "\n",
      "    testp = list(set(all_p) - set(s))\n",
      "    if pratio != 1:\n",
      "        testp *= pratio\n",
      "#         ntestp = len(testp)\n",
      "#         boot_ntestp = int(ntestp*pratio)\n",
      "#         w = np.ones(ntestp)/float(ntestp)\n",
      "#         testp = [testp[i] for i, n in enumerate(np.random.multinomial(boot_ntestp, w))\n",
      "#                  for k in xrange(n)]\n",
      "        \n",
      "    testn = list(set(all_n) - set(n))\n",
      "    sample_test = testp + testn\n",
      "    random.shuffle(sample_test)\n",
      "\n",
      "    return sample_test, sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from gradient_boost_loss import NAUC\n",
      "import os\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    space = args.get('space')\n",
      "    pratio = int(space['pratio'])\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    assert y_trn.mean() > 0.01 and y_trn.mean() < 0.99\n",
      "\n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    def t_est(args):\n",
      "        try:\n",
      "            from sklearn.ensemble import GradientBoostingClassifier \n",
      "            est = GradientBoostingClassifier()\n",
      "            params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "            est.set_params(**params)\n",
      "#             est.loss__ = NAUC(2)\n",
      "\n",
      "            nf = int(args['nf'])\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])[:,1]\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])[:,1]\n",
      "            \n",
      "            from sklearn.metrics import roc_auc_score\n",
      "            train_score = roc_auc_score(y_trn, y_train)\n",
      "            validate_score = roc_auc_score(y_val, y_validate)\n",
      "            \n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, os.getpid(), args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'pid':os.getpid(),\n",
      "                    'train_score':train_score, 'validate_score':validate_score}\n",
      "        except Exception as e:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('../data-cache/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', e, args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 100)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "#     trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals) #, trials=trials)\n",
      "#     import cPickle as pickle\n",
      "#     lock = LockFile('.lock')\n",
      "#     with lock:\n",
      "#         with open('../data-cache/hyperopt.spkl','ab') as fp:\n",
      "#                 pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hyper-parameter search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'n_estimators': 1000,\n",
      "    'pratio': 1,\n",
      "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(1.)),\n",
      "    'nf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'max_features': hp.quniform( 'max_features', 10, 30, 1),\n",
      "    'max_depth': hp.quniform( 'max_depth', 2, 18, 1),\n",
      "    'min_samples_leaf': hp.quniform( 'min_samples_leaf', 2, 30, 1),\n",
      "#     'subsample': hp.uniform( 'subsample', 0.2, 0.9),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:46]: \u001b[0m\n",
        "{'learning_rate': 0.016273346783129052,\n",
        " 'max_depth': 6.0,\n",
        " 'max_features': 14.0,\n",
        " 'min_samples_leaf': 3.0,\n",
        " 'nf': 172.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:46]: \u001b[0m\n",
        "{'learning_rate': 0.7477400914297095,\n",
        " 'max_depth': 6.0,\n",
        " 'max_features': 18.0,\n",
        " 'min_samples_leaf': 8.0,\n",
        " 'nf': 153.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:46]: \u001b[0m\n",
        "{'learning_rate': 0.056923904333768996,\n",
        " 'max_depth': 6.0,\n",
        " 'max_features': 10.0,\n",
        " 'min_samples_leaf': 14.0,\n",
        " 'nf': 11.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:46]: \u001b[0m\n",
        "{'learning_rate': 0.035907527443119265,\n",
        " 'max_depth': 14.0,\n",
        " 'max_features': 18.0,\n",
        " 'min_samples_leaf': 18.0,\n",
        " 'nf': 18.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:46]: \u001b[0m\n",
        "{'learning_rate': 0.26840910401979023,\n",
        " 'max_depth': 10.0,\n",
        " 'max_features': 23.0,\n",
        " 'min_samples_leaf': 21.0,\n",
        " 'nf': 121.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:46]: \u001b[0m\n",
        "{'learning_rate': 0.833610267905131,\n",
        " 'max_depth': 3.0,\n",
        " 'max_features': 22.0,\n",
        " 'min_samples_leaf': 10.0,\n",
        " 'nf': 278.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:46]: \u001b[0m\n",
        "{'learning_rate': 0.0074829147858297045,\n",
        " 'max_depth': 9.0,\n",
        " 'max_features': 10.0,\n",
        " 'min_samples_leaf': 23.0,\n",
        " 'nf': 15.0}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:46]: \u001b[0m\n",
        "{'learning_rate': 0.743130006310607,\n",
        " 'max_depth': 6.0,\n",
        " 'max_features': 16.0,\n",
        " 'min_samples_leaf': 22.0,\n",
        " 'nf': 96.0}"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r ../data-cache/hyperopt.txt > ../data-cache/hyperopt.sort.txt\n",
      "!head -n 5 ../data-cache/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0 1.0 1387 {'n_estimators': 1000, 'pratio': 1, 'max_features': 16.0, 'learning_rate': 0.743130006310607, 'max_depth': 6.0, 'nf': 96.0, 'min_samples_leaf': 22.0}\r\n",
        "1.0 1.0 1377 {'n_estimators': 1000, 'pratio': 1, 'max_features': 23.0, 'learning_rate': 0.26840910401979023, 'max_depth': 10.0, 'nf': 121.0, 'min_samples_leaf': 21.0}\r\n",
        "1.0 1.0 1372 {'n_estimators': 1000, 'pratio': 1, 'max_features': 14.0, 'learning_rate': 0.016273346783129052, 'max_depth': 6.0, 'nf': 172.0, 'min_samples_leaf': 3.0}\r\n",
        "0.998188405797 1.0 1386 {'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'learning_rate': 0.0074829147858297045, 'max_depth': 9.0, 'nf': 15.0, 'min_samples_leaf': 23.0}\r\n",
        "0.998188405797 1.0 1377 {'n_estimators': 1000, 'pratio': 1, 'max_features': 22.0, 'learning_rate': 0.08421933314518218, 'max_depth': 15.0, 'nf': 176.0, 'min_samples_leaf': 26.0}\r\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = float(l[0])\n",
      "    train_score = float(l[1])\n",
      "    pid = int(l[2])\n",
      "    args = eval(''.join(l[3:]))\n",
      "    hyeropt_results.append((validate_score, train_score, pid, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "774"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Nt, NFF = Xt.shape\n",
      "assert NF == NFF\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "(150, 480)"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (Nt, NF)\n",
      "mmXt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = Xt[:,pn_importance_order]\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "    pratio = int(args.get('pratio',1))\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split(pratio=pratio)    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    est = GradientBoostingClassifier()\n",
      "\n",
      "    params = dict((k,int(v) if isinstance(v, float) and abs(v - int(v)) < 1e-3 else v)\n",
      "                          for k, v in args.iteritems() if k not in ['nf', 'pratio'])\n",
      "    est.set_params(**params)\n",
      "#     est.loss__ = NAUC(2)\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('../data-cache/validate.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('../data-cache/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return roc_auc_score(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data-cache/validate.spkl\n",
      "!rm ../data-cache/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "pid2args_list = defaultdict(list)\n",
      "for res in hyeropt_results:\n",
      "    validation_score = res[0]\n",
      "    test_score = res[1]\n",
      "    pid = res[2]\n",
      "    args = res[3]\n",
      "    pid2args_list[pid].append((validation_score, args))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for v in pid2args_list.values():\n",
      "    print v[1]\n",
      "    for vv in v[:4]:\n",
      "        args_list.append(vv[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.923913043478, {'learning_rate': 0.3127277707970103, 'nf': 16.0, 'min_samples_leaf': 14.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 12.0, 'max_depth': 18.0})\n",
        "(0.998188405797, {'learning_rate': 0.08421933314518218, 'nf': 176.0, 'min_samples_leaf': 26.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 22.0, 'max_depth': 15.0})\n",
        "(0.86231884058, {'learning_rate': 0.0051556466791173195, 'nf': 300.0, 'min_samples_leaf': 2.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 26.0, 'max_depth': 7.0})\n",
        "(0.996376811594, {'learning_rate': 0.009379599636176498, 'nf': 16.0, 'min_samples_leaf': 25.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 15.0, 'max_depth': 9.0})\n",
        "(0.994565217391, {'learning_rate': 0.16266020779091664, 'nf': 158.0, 'min_samples_leaf': 20.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 18.0, 'max_depth': 10.0})\n",
        "(0.998188405797, {'learning_rate': 0.012325309500310029, 'nf': 177.0, 'min_samples_leaf': 5.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 17.0, 'max_depth': 3.0})\n",
        "(0.965579710145, {'learning_rate': 0.9885380412204035, 'nf': 151.0, 'min_samples_leaf': 14.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 18.0, 'max_depth': 7.0})\n",
        "(0.916666666667, {'learning_rate': 0.4339857336888007, 'nf': 27.0, 'min_samples_leaf': 15.0, 'n_estimators': 1000, 'pratio': 1, 'max_features': 10.0, 'max_depth': 14.0})\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "[{'learning_rate': 0.035907527443119265,\n",
        "  'max_depth': 14.0,\n",
        "  'max_features': 18.0,\n",
        "  'min_samples_leaf': 18.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 18.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.3127277707970103,\n",
        "  'max_depth': 18.0,\n",
        "  'max_features': 12.0,\n",
        "  'min_samples_leaf': 14.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 16.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.05785381661813288,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 17.0,\n",
        "  'min_samples_leaf': 14.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 20.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.2015009395794558,\n",
        "  'max_depth': 18.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 12.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 15.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.26840910401979023,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 23.0,\n",
        "  'min_samples_leaf': 21.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 121.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.08421933314518218,\n",
        "  'max_depth': 15.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 26.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 176.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.014994719213255552,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 29.0,\n",
        "  'min_samples_leaf': 23.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 164.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.06586998196882567,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 25.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 220.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.833610267905131,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 10.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 278.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0051556466791173195,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 26.0,\n",
        "  'min_samples_leaf': 2.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 300.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.003708153712561447,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 26.0,\n",
        "  'min_samples_leaf': 2.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 272.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.011131561641445346,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 26.0,\n",
        "  'min_samples_leaf': 2.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 280.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.0074829147858297045,\n",
        "  'max_depth': 9.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 23.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 15.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.009379599636176498,\n",
        "  'max_depth': 9.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 25.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 16.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.012415662877131658,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 11.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 13.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.004753262257803044,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 27.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 17.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.743130006310607,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 16.0,\n",
        "  'min_samples_leaf': 22.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 96.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.16266020779091664,\n",
        "  'max_depth': 10.0,\n",
        "  'max_features': 18.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 158.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.5194164418581994,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 26.0,\n",
        "  'min_samples_leaf': 19.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 115.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.26961474915074457,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 91.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.016273346783129052,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 14.0,\n",
        "  'min_samples_leaf': 3.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 172.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.012325309500310029,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 17.0,\n",
        "  'min_samples_leaf': 5.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 177.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.2099907912434229,\n",
        "  'max_depth': 14.0,\n",
        "  'max_features': 12.0,\n",
        "  'min_samples_leaf': 4.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 99.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.01139410422156201,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 3.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 229.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.7477400914297095,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 18.0,\n",
        "  'min_samples_leaf': 8.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 153.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.9885380412204035,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 18.0,\n",
        "  'min_samples_leaf': 14.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 151.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.833610267905131,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 22.0,\n",
        "  'min_samples_leaf': 10.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 278.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.3578316550030738,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 16.0,\n",
        "  'min_samples_leaf': 19.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 28.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.056923904333768996,\n",
        "  'max_depth': 6.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 14.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 11.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.4339857336888007,\n",
        "  'max_depth': 14.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 15.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 27.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.05429269285657218,\n",
        "  'max_depth': 7.0,\n",
        "  'max_features': 10.0,\n",
        "  'min_samples_leaf': 20.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 11.0,\n",
        "  'pratio': 1},\n",
        " {'learning_rate': 0.04928345549155947,\n",
        "  'max_depth': 3.0,\n",
        "  'max_features': 15.0,\n",
        "  'min_samples_leaf': 19.0,\n",
        "  'n_estimators': 1000,\n",
        "  'nf': 40.0,\n",
        "  'pratio': 1}]"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.965579710145\n",
        "0.880434782609\n",
        "0.990942028986\n",
        "0.891304347826\n",
        "0.686594202899\n",
        "0.115942028986\n",
        "0.75"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.967391304348\n",
        "0.266304347826\n",
        "0.182971014493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.974637681159"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.836956521739\n",
        "0.856884057971\n",
        "0.945652173913\n",
        "1.0\n",
        "0.740942028986\n",
        "0.545289855072\n",
        "0.972826086957\n",
        "0.826086956522\n",
        "0.563405797101\n",
        "0.971014492754\n",
        "0.980072463768\n",
        "0.905797101449\n",
        "0.650362318841\n",
        "0.786231884058\n",
        "0.295289855072\n",
        "0.184782608696\n",
        "0.505434782609\n",
        "0.938405797101\n",
        "0.26268115942\n",
        "0.855072463768\n",
        "0.833333333333\n",
        "0.675724637681\n",
        "0.842391304348\n",
        "0.938405797101\n",
        "0.659420289855\n",
        "0.771739130435\n",
        "0.0326086956522\n",
        "0.480072463768\n",
        "0.971014492754\n",
        "0.579710144928\n",
        "0.989130434783"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.235507246377"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.143115942029\n",
        "0.871376811594\n",
        "0.998188405797\n",
        "0.688405797101\n",
        "0.646739130435\n",
        "0.530797101449\n",
        "0.648550724638\n",
        "0.217391304348\n",
        "0.523550724638\n",
        "0.632246376812\n",
        "0.184782608696\n",
        "0.721014492754\n",
        "0.54347826087\n",
        "0.724637681159\n",
        "0.695652173913\n",
        "0.463768115942\n",
        "0.608695652174\n",
        "0.485507246377\n",
        "0.860507246377\n",
        "0.884963768116\n",
        "0.759057971014\n",
        "0.882246376812\n",
        "0.972826086957\n",
        "1.0\n",
        "0.842391304348\n",
        "0.833333333333\n",
        "0.858695652174\n",
        "0.994565217391\n",
        "0.54347826087\n",
        "0.885869565217\n",
        "0.253623188406"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.833333333333"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.833333333333\n",
        "0.275362318841\n",
        "1.0\n",
        "1.0\n",
        "0.983695652174\n",
        "0.967391304348\n",
        "0.742753623188\n",
        "0.452898550725\n",
        "0.619565217391\n",
        "0.550724637681\n",
        "0.822463768116\n",
        "0.963768115942\n",
        "0.990942028986\n",
        "0.54347826087\n",
        "0.594202898551\n",
        "0.150362318841\n",
        "0.226449275362\n",
        "0.574275362319\n",
        "0.980072463768\n",
        "0.657608695652\n",
        "0.717391304348\n",
        "0.889492753623\n",
        "0.692028985507\n",
        "0.143115942029\n",
        "0.869565217391\n",
        "0.827898550725\n",
        "0.726449275362\n",
        "0.467391304348\n",
        "0.815217391304\n",
        "0.679347826087\n",
        "0.541666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.400362318841"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.547101449275\n",
        "0.79347826087\n",
        "0.951086956522\n",
        "0.949275362319\n",
        "0.248188405797\n",
        "0.731884057971\n",
        "0.981884057971\n",
        "0.822463768116\n",
        "0.992753623188\n",
        "0.650362318841\n",
        "0.530797101449\n",
        "0.856884057971\n",
        "0.527173913043\n",
        "0.684782608696\n",
        "0.889492753623\n",
        "0.958333333333\n",
        "0.985507246377\n",
        "0.846014492754\n",
        "0.902173913043\n",
        "0.853260869565\n",
        "0.751811594203\n",
        "0.925724637681\n",
        "0.784420289855\n",
        "0.972826086957\n",
        "0.773550724638\n",
        "0.733695652174\n",
        "0.0724637681159\n",
        "0.68115942029\n",
        "0.188405797101\n",
        "0.516304347826\n",
        "0.856884057971"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.927536231884"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.217391304348\n",
        "0.672101449275\n",
        "0.961956521739\n",
        "0.998188405797\n",
        "0.916666666667\n",
        "0.626811594203\n",
        "0.43115942029\n",
        "0.936594202899\n",
        "0.846014492754\n",
        "0.539855072464\n",
        "0.876811594203\n",
        "0.161231884058\n",
        "0.653985507246\n",
        "0.860507246377\n",
        "0.652173913043\n",
        "0.746376811594\n",
        "1.0\n",
        "0.884057971014\n",
        "0.846014492754\n",
        "1.0\n",
        "0.610507246377\n",
        "0.461956521739\n",
        "0.95652173913\n",
        "0.969202898551\n",
        "0.465579710145\n",
        "0.289855072464\n",
        "1.0\n",
        "0.746376811594\n",
        "0.942028985507\n",
        "0.541666666667\n",
        "0.925724637681"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.91847826087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.342391304348\n",
        "0.996376811594\n",
        "0.949275362319\n",
        "0.742753623188\n",
        "0.869565217391\n",
        "0.978260869565\n",
        "0.878623188406\n",
        "0.965579710145\n",
        "0.813405797101\n",
        "0.452898550725\n",
        "0.748188405797\n",
        "0.764492753623\n",
        "0.976449275362\n",
        "0.88768115942\n",
        "0.530797101449\n",
        "0.13768115942\n",
        "0.692028985507\n",
        "0.798913043478\n",
        "0.771739130435\n",
        "0.967391304348\n",
        "0.58152173913\n",
        "0.900362318841\n",
        "0.753623188406\n",
        "0.13768115942\n",
        "0.684782608696\n",
        "0.780797101449\n",
        "0.971014492754\n",
        "0.920289855072\n",
        "0.480072463768\n",
        "0.628623188406\n",
        "0.83152173913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.186594202899"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.992753623188\n",
        "0.969202898551\n",
        "0.786231884058\n",
        "0.753623188406\n",
        "0.659420289855\n",
        "0.573369565217\n",
        "0.992753623188\n",
        "0.934782608696\n",
        "0.989130434783\n",
        "1.0\n",
        "0.5\n",
        "0.385869565217\n",
        "0.135869565217\n",
        "0.768115942029\n",
        "0.289855072464\n",
        "0.690217391304\n",
        "0.95652173913\n",
        "0.677536231884\n",
        "0.869565217391\n",
        "0.670289855072\n",
        "0.994565217391\n",
        "0.940217391304\n",
        "0.784420289855\n",
        "0.335144927536\n",
        "0.98731884058\n",
        "0.297101449275\n",
        "0.596014492754\n",
        "0.711956521739\n",
        "0.0108695652174\n",
        "0.467391304348\n",
        "0.867753623188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.740942028986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.708333333333\n",
        "0.829710144928\n",
        "0.920289855072\n",
        "0.75\n",
        "0.989130434783\n",
        "0.472826086957\n",
        "0.534420289855\n",
        "0.161231884058\n",
        "0.536231884058\n",
        "0.518115942029\n",
        "0.798913043478\n",
        "0.672101449275\n",
        "0.985507246377\n",
        "0.630434782609\n",
        "1.0\n",
        "0.0615942028986\n",
        "0.590579710145\n",
        "0.474637681159\n",
        "0.811594202899\n",
        "0.922101449275\n",
        "0.454710144928\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('../data-cache/validate.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_count == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "roc_auc_score(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "0.74867724867724872"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../data-cache/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 141107-GBC-combine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}