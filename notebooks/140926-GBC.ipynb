{
 "metadata": {
  "name": "",
  "signature": "sha256:046ceb86e3380b04676259a9d7df8224f795cc401d3f3f50d009fbc989e18f55"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually run this notebooks on all targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = 'Patient_2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from matplotlib import pylab as pl\n",
      "import cPickle as pickle\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "from common.data import CachedDataLoader\n",
      "cached_data_loader = CachedDataLoader('../data-cache')\n",
      "def read_data(target, data_type, features):\n",
      "    return cached_data_loader.load('data_%s_%s_%s'%(data_type,target,features),None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1112
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FEATURES = 'gen-8_medianwindow-bands2-usf-w60-b0.2-b4-b8-b12-b30-b70-0.1-0.5-0.9'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LOCAL_HOSTNAME=!hostname\n",
      "if LOCAL_HOSTNAME[0].startswith('ip-'):\n",
      "    !aws s3 cp s3://udikaggle/sezure/{FEATURES}.tgz data-cache/\n",
      "    !tar xfz data-cache/{FEATURES}.tgz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "each target receive a different model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "positive examples. The positive examles were upsampled (using `gen_ictal=-8`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdata = read_data(target, 'preictal', FEATURES)\n",
      "Np, NF = pdata.X.shape\n",
      "Np, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1115,
       "text": [
        "(138, 360)"
       ]
      }
     ],
     "prompt_number": 1115
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "negative examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndata = read_data(target, 'interictal', FEATURES)\n",
      "Nn, NF = ndata.X.shape\n",
      "Nn, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1116,
       "text": [
        "(42, 360)"
       ]
      }
     ],
     "prompt_number": 1116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data is broken into segments that should be taken together when splitting to training and validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getsegments(pdata):\n",
      "    segments = []\n",
      "    start = 0\n",
      "    last_l = 0\n",
      "    for i,l in enumerate(pdata.latencies):\n",
      "        if l<last_l:\n",
      "            segments.append(range(start,i))\n",
      "            start = i\n",
      "        last_l = l\n",
      "    segments.append(range(start,i+1))\n",
      "    return segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psegments = getsegments(pdata)\n",
      "Nps = len(psegments)\n",
      "nsegments = getsegments(ndata)\n",
      "Nns = len(nsegments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npratio = float(Nn)/Np\n",
      "print target,1/(1+npratio),Np,Nn\n",
      "npsratio = float(Nns)/Nps\n",
      "print target,1/(1+npsratio),Nps,Nns\n",
      "Ntrainps = 1\n",
      "Ntrainns = int(Ntrainps*npsratio)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Patient_2 0.766666666667 138 42\n",
        "Patient_2 0.3 3 7\n"
       ]
      }
     ],
     "prompt_number": 1119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.concatenate((pdata.X, ndata.X))\n",
      "y = np.zeros(X.shape[0])\n",
      "y[:pdata.X.shape[0]] = 1\n",
      "nsegments = [[s+Np for s in ns] for ns in nsegments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latencies = np.concatenate((pdata.latencies,ndata.latencies))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N, NF = X.shape\n",
      "N, NF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1122,
       "text": [
        "(180, 360)"
       ]
      }
     ],
     "prompt_number": 1122
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Importance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Positive/Negative feature importance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using RF because it needs very little (hyper) parameter tuning. On purpose I am using a small depth, because I am not interested in the best prediction (which is already high) but with the feature importance after taking into account pair interactions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=2)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1123,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=2, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=1000, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 1123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1124,
       "text": [
        "0.90000000000000002"
       ]
      }
     ],
     "prompt_number": 1124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pnweights = rf.feature_importances_\n",
      "pn_importance_order = pnweights.argsort()[::-1]\n",
      "pl.plot(rf.feature_importances_[pn_importance_order])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1125,
       "text": [
        "[<matplotlib.lines.Line2D at 0x11fe174d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt0XOV97vHv3CRZV18ly7IVGYyxXeRgkxg3qEACSY1D\nMeSQUEgwpahQXCc5SdNicnLhpOskkIYk5dAatzg5DiGYLFgQ0wA2TiGJGjAxviDAxnfkmyRb8lWS\npZFmzh/vHmk81mhG1pbm3dLzWWuW9uXdM482Zn7a77svICIiIiIiIiIiIiIiIiIiIiIiIiIiMugW\nANuBncB9Sdo84qzfCsxJWBcANgMvxC17ADjgLN/sfIaIiFguAOwCKoAQsAWYmdBmIfCiM3058EbC\n+q8CTwJr4pZ921kuIiIW8adYPw9TFPYBYWA1sCihzQ3AKmd6AzAaKHHmJ2OKxuOAL2G7xHkREcmw\nVEWhDNgfN3/AWZZumx8B/wBEennvL2K6m1ZiComIiGRYqqIQTfN9ejsKuB5oxIwZJK5fDkwFLgUO\nAw+n+TkiIjKIginWHwSmxM1PwRwJ9NVmsrPsf2C6lhYCOUAh8DNgMaZYxDzO2YPQ3Z588sloSUlJ\nb6tERKQXhw8f3n377bdPO9/tUxWFjcBFmIHmQ8AtwK0JbdYASzHjDfOB40A98HXnBXAV8DVMQQAo\nxRwhANwE1Pb24SUlJcydOze93yRDHnzwQZYtW5bpGCkpp7uU013K6Z5NmzZdOJDtUxWFTswX/lrM\nmUgrgW3APc76FZgzjxZiBqRbgDuTvFd8V9RDmK6jKLA37v08p66uLtMR0qKc7lJOdymnPVIVBYCX\nnFe8FQnzS1O8x2+dV8ziZA1FRCRzUg00Swq33XZbpiOkRTndpZzuUk57WH2twPr166O2jymIiNhk\n06ZNXHvttef93a4jhQGqqanJdIS0KKe7lNNdymkPFQUREemm7iMRkWFE3UciIuIaFYUB8kofo3K6\nSzndpZz2sL4odEbSvf2SiIgMlPVjChUzKhmbG8p0FBERTxj2YwonznRmOoKIyIhhfVE41W53UfBK\nH6Nyuks53aWc9rC+KJw405XpCCIiI4b1YwoHcqZww6wJmY4iIuIJw35MYd+xM5mOICIyYlhfFHY3\ntWY6Qp+80seonO5STncppz2sLwp7ms/QpWsVRESGRDpFYQGwHdgJ3JekzSPO+q3AnIR1AWAzZz+H\neSzwCrADWAeMTvbh7Z0RDp5oTyNmZlRVVWU6QlqU013K6S7ltEeqohAAHsUUhlmY5zPPTGizEJiG\neZbz3cDyhPVfBt7j7MdxLsMUhenAb5z5pJrbwiliioiIG1IVhXmYZy/vA8LAamBRQpsbgFXO9AbM\nX/0lzvxkTNF4nLPPdIrfZhVwY18hIlF7u4+80seonO5STncppz1SFYUyYH/c/AFnWbptfgT8AxBJ\n2KYEaHCmG+gpIr3SkIKIyNAIplif7tdx4jmxPuB6oBEznnB1is9I+jl7nn6IVXtmsr4wm6KiIior\nK7v79WJVO9PzMbbk6W2+qqrKqjzan9qf2p/u5ampqaGurg6A6upqBiLVBQ7zgQcwYwoA92P+6n8o\nrs1jwGuYriUwg9JXA18Cbgc6gRygEHgWWBzXph4oBV4FZiR++Pr166PLNvn4zqcuYH55UX9+LxGR\nEWmwL17biBlArgCygFuANQlt1mC+6MEUkeOYL/uvA1OAqcBfAv8V124NcIczfQfwfF8hNKYwcMrp\nLuV0l3LaI1X3USewFFiLORNpJbANuMdZvwJ4ETOYvAtoAe5M8l7x3+wPAr8E7sIMYn+urxCRxBEJ\nEREZFNbf+2jZJh/fuKaCK6eOyXQcERHrDft7H4GOFEREhoo3ioLGFAZMOd2lnO5STnt4pChkOoGI\nyMjgiTGFr11Zzqemj8t0HBER642MMQUdKYiIDAmPFAV7q4JX+hiV013K6S7ltIdHikKmE4iIjAye\nGFNY+rHJek6ziEgaNKYgIiKu8UhRsLcqeKWPUTndpZzuUk57eKMo6FBBRGRIeGJMoXreJD43u8/n\n8IiICCNmTEFHCiIiQ8EbRcHiG+J5pY9ROd2lnO5STnt4oyjoSEFEZEh4YkzhC3Mmsviy0kzHERGx\n3lCMKSzAPFN5J3BfkjaPOOu3AnOcZTnABmAL8B7wvbj2DwAHgM3OawF90JGCiMjQSFUUAsCjmC/t\nWcCtwMyENguBaZhnOd8NLHeWnwE+DlwKzHamr3DWRYEfYgrIHODlvkLYfEaqV/oYldNdyuku5bRH\nqqIwD/Ps5X1AGFgNLEpocwOwypneAIwGYuePtjo/szAF5ljcdmkf3uhIQURkaKQqCmXA/rj5A86y\nVG0mO9MBTPdRA/Aqphsp5ouY7qaVmEKSlM1HClVVVZmOkBbldJdyuks57RFMsT7dr+PEv/pj23Vh\nuo+KgLXA1cBrmC6m7zht/gl4GLirtzfe8/RDrNtyAc2vFlJUVERlZWX3f5jYoZzmNa95zY/U+dh0\nXV0dANXV1QxEqi6c+ZhB4dhA8P1ABHgors1jmC/61c78duAqzNFBvG8CbcAPEpZXAC8AlYkfHjv7\n6MY/mcCSP52cuNoKNTU1nvjrQTndpZzuUk73DPbZRxsxA8gVmHGBW4A1CW3WAIud6fnAcUxBGE9P\nt9Ao4JOYM40A4s8vvQmo7SuExhRERIZGOtXkOuDHmPGBlZhTS+9x1q1wfsbOUGoB7gQ2Yf7yX4Up\nPH7gCeCfnfY/w3QrRYG9zvslHll0HylcP3M8X7piSn9/NxGREWegRwqpxhQAXnJe8VYkzC/tZbta\nYG6S91ycZHmvdKQgIjI0vHGbC937aMCU013K6S7ltIc3ioKOFEREhoQn7n107UVj+cerPpTpOCIi\n1hsZz1Ow+eo1EZFhxBtFweLuI6/0MSqnu5TTXcppD48UhUwnEBEZGTwxplBVMZpvXTs103FERKw3\nMsYULO4+EhEZTlQUBsgrfYzK6S7ldJdy2sMjRSHTCURERgZPjCl8ZHIB310wLdNxRESsN0LGFDKd\nQERkZPBIUbC3Knilj1E53aWc7lJOe3ijKFh8QzwRkeHEE2MKl0zM44fXT890HBER642MMQUdKYiI\nDIl0isICzHOXdwL3JWnziLN+KzDHWZYDbAC2AO9hntgWMxZ4BdgBrKPnsZ290pjCwCmnu5TTXcpp\nj1RFIUDPozZnAbcCMxPaLASmYZ7lfDew3Fl+Bvg45rGbs53pK5x1yzBFYTrwG2c+KZ19JCIyNFIV\nhXnALmAfEAZWA4sS2tyAeRYzmCOD0UCJM9/q/MzCFJhjvWyzCrixrxA2HylUVVVlOkJalNNdyuku\n5bRHqqJQBuyPmz/gLEvVZrIzHcB0HzUAr2K6kcAUjQZnuoGeItIrHSmIiAyNYIr16X4dJ450x7br\nwnQfFQFrgauB13ppm/Rz9jz9EC2TJvPgjvEUFRVRWVnZXa1j/XuZnK+treXee++1Jk+y+fi+UBvy\naH9qf2p/ujMfm66rqwOgurqagUh12tJ84AHMmALA/UAEeCiuzWOYL/rVzvx24Cp6jgRivonpTnrY\naXM1UA+UYo4iZiR+eOyU1PLROTx+c+JQhh1qamo8cUipnO5STncpp3sG+5TUjZgB5ArMuMAtwJqE\nNmuAxc70fOA4piCMp+esolHAJzFdSbFt7nCm7wCe7yuExhQGTjndpZzuUk57pOo+6gSWYrp+AsBK\nYBtwj7N+BfAi5gykXUALcKezrhQziOx3Xk9gzjQCeBD4JXAXZhD7c32F0JiCiMjQSOc6hZeAizGn\nncauNVjhvGKWOus/DGxyltUCc+k5JfWf49o3A9diTkn9FOboIimbjxS8ct6ycrpLOd2lnPbwxhXN\nFhcFEZHhxBP3PhqfF+IXt16S6TgiItYbGfc+0pGCiMiQ8EZRsPiGeF7pY1ROdymnu5TTHt4oCjpS\nEBEZEp4YUyjIDvDs7bMzHUdExHojYkyhSxcqiIgMCU8UBZtrglf6GJXTXcrpLuW0h0eKgsVVQURk\nGPHEmELI7+PXf31ppuOIiFhvZIwp6EhBRGRIeKIoaExh4JTTXcrpLuW0hyeKAmhcQURkKFg/pvD1\nzT4iUXjpry8l4Lc6rohIxg37MQW/z/xuGlcQERl86RSFBZjHZ+4E7kvS5hFn/VZgjrNsCuYxm+8C\n7wBfimv/AHAA2Oy8FpBE7ODA1nEFr/QxKqe7lNNdymmPVE9eCwCPYh6IcxD4I+ZRmtvi2izEPGDn\nIuByYDnmsZxh4CuYR3DmA28B6zAFJgr80Hn1yRwpRInYWhVERIaRVEcK8zCP2dyH+ZJfDSxKaHMD\n5rGbABswz2UuAerpeSbzaUwhKYvbLq0+r9iRgq0lwSvPbFVOdymnu5TTHqmKQhmwP27+AGd/sSdr\nMzmhTQWmW2lD3LIvYrqbVmIKSe8BY2MKOlIQERl0qYpCut/EiX/1x2+XDzwDfBlzxACmi2kq5vnN\nh4GHkwbsHlOwsyh4pY9ROd2lnO5STnukGlM4iBkwjpmCORLoq81kZxlACHgW+DnwfFybxrjpx4EX\nkgXY+dSDdOYX8926cUwtHU9lZWX3IVzsP1Am52tra63K4/V57U/tT5vnbdyfsem6ujoAqqurGYhU\n/fpB4H3gGuAQ8CZwK+cONC91fs4Hfuz89GHGGpowA87xSjFHCDjrPgrclvjh69evj750bAy/3Xuc\nr11Zzqemj0v/NxMRGYEGep1CqiOFTswX/lrMmUgrMQXhHmf9CuBFTEHYBbQAdzrrrgC+ALyNOe0U\n4H7gZeAhTNdRFNgb937nmDp2FL/de5y9zW39+b1EROQ8pHOdwkvAxZjTTr/nLFvhvGKWOus/DGxy\nltU4738pZpB5DqYgACwGZjvtbwQakn341LGjANjTfCaNqEPPK32Myuku5XSXctrD+iuap47NAeCD\nYzpSEBEZbFbfTGj9+vXRS+fM4S9+upVwJMqv7pjNqFAg07FERKw1Iu59VJyfBUDD6Y4MpxERGd6s\nLwoApYWmKBw+aV9R8Eofo3K6SzndpZz28ERRmJifDUD9qfYMJxERGd68URQKzJFCvYXdR165F4py\nuks53aWc9vBGUXC6j3YfbbP2dhciIsOBJ4rCjAl5hPw+3q4/zS+2JL2kISO80seonO5STncppz08\nURSK87P45rVTAXh6Sz1NLeEMJxIRGZ6sv05h7ty53fPfWrebN+pOcu/8Mm66pDiDyURE7DTsr1OI\nN31CHgDH2zoznEREZHjyVFEYnWPu33f8jD1FwSt9jMrpLuV0l3Law1NFoTDH3OLihEVFQURkOPFU\nUYgdKZy0qCh45bxl5XSXcrpLOe3hqaJQZGH3kYjIcOKpolDoFAWbuo+80seonO5STncppz3SKQoL\ngO3ATuC+JG0ecdZvxTxMB8xzm18F3gXeAb4U134s8AqwA1gHjE4nbGF2EB9wur2LroiubBYRcVuq\nc1kDmGc0XwscBP5I389ovhz4F8wzmic6ry1APvAWsAhTYL4PHHV+3geMAZYlfnjidQoANz/xNifb\nu3j685cwZlSoH7+qiMjwN9jXKczDPHt5HxAGVmO+2OPdAKxypjdg/uovAeoxBQHgNKaQlPWyzSrM\nIznTYmMXkojIcJGqKJQB++PmD9Dzxd5Xm8kJbSow3UobnPkSep7L3ODMpyV2BtIJSy5g80ofo3K6\nSzndpZz2SFUU0u24TzxUid8uH3gG+DLmiKG3z0h7gGBMrukyarakKIiIDCfBFOsPYgaMY6ZgjgT6\najPZWQYQAp4Ffg48H9emATPeUA+UAo3JAixZsoTy8nIAioqKOOGfCIEKmlrD3VU7du5wpuZjbMnT\n23xVVZVVebQ/tT+1P93LU1NTQ11dHQDV1dUMRKrBiCBmoPka4BDwJn0PNM8Hfuz89GHGC5qAryS8\n7/ed5Q9hBphHk+ZA89NbG1j5x0PcXFnM3Zcn9mSJiIxsgz3Q3In5wl8LvAc8jSkI9zgvgBeBPZgB\n6RXAEmf5FcAXgI8Dm53XAmfdg8AnMaekfsKZT8s4p/uoqdWO22d7pY9ROd2lnO5STnuk6j4CeMl5\nxVuRML+0l+1qSF50mjGnufZbd1HQMxVERFznqecpANQdO0P1s9soK8zmp5+blaFkIiJ2GlHPUwAY\nlxc7+0hHCiIibvNcUcgN+ckO+GgLR2jp6Mp0HM/0MSqnu5TTXcppD88VBZ/Px6TCbAD2NLdlOI2I\nyPDiuTEFgP/73/t5YdtR/uqyUm6bMzEDyURE7DTixhQAZpfmA1Bb39sF0iIicr48WRQqJ5qi8F5j\nC5FoZm+h7ZU+RuV0l3K6Sznt4cmiMDY3xPjcEG3hCIdPtmc6jojIsOHJMQWAb67dzYb9J/nGNRVc\nOXXMECcTEbHTiBxTALhg3CgAdjfpDCQREbd4tihcONYUhV1HM1sUvNLHqJzuUk53Kac9PFsUZhTn\nAfB2/WnaOyMZTiMiMjx4dkwBYOnz77PjaCufnzORxXMn4vNZ/euIiAy6ETumAFA1tQiAJzfX8x9v\nHspwGhER7/N0Ubh+xngWTB8HwDO1jfxmV/OQZ/BKH6Nyuks53aWc9vB0UcjPDvLVK8v50hXmaaA/\n/n0dv91zLMOpRES8K51+pwWYR2wGgMcxj9BM9AhwHdAK/BXmKWsAPwE+jXkGc2Vc+weAauCIM38/\n8HLim6YaU4iJRqP84Hd1vLKzmVEhP88tno1f4wsiMgIN9phCAHgUUxhmYZ7PPDOhzUJgGnARcDew\nPG7dT+l5BGe8KPBDYI7zOqcg9IfP5+NrV5aTHfTTFo5wrK1zIG8nIjJipSoK8zDPXt4HhIHVwKKE\nNjcAq5zpDcBoIHbr0t8DyfpzXP1T3ufzMaXI3FK78XSHm2/dJ6/0MSqnu5TTXcppj1RFoQzYHzd/\nwFnW3za9+SKwFViJKSQDVpKfBQxtURARGU6CKdanewvSxL/6U223HPiOM/1PwMPAXb01XLJkCeXl\n5QAUFRVRWVlJVVUV0FO1Y/On92zl5L7jNM6b1Ov6wZqPGarPO5/5qqoqq/Jof2p/an+6l6empoa6\nujoAqqurGYhUXTjzMYPCsXGB+4EIZw82Pwa8hulaAtgOXAU0OPMVwAucPdAcL+n6dAeaY56tbWTF\nhoMsmjWev/vYlLS3ExEZLgZ7oHkjZgC5AsgCbgHWJLRZAyx2pucDx+kpCMmUxk3fBNSmkTWlYqf7\naOcQ3g/JK32Myuku5XSXctojVVHoBJYCa4H3gKeBbcA9zgvgRWAPZkB6BbAkbvungD8A0zHjDnc6\nyx8C3saMKVwFfGWAvwcA5aPNQPN7jS3c+9x29h3THVRFRPrD6pP5+9t9BPDcO40sf+MgAJ+5ZAJ/\nO3/yYEQTEbHSiL73UW9uuqSYb10zFdCzFkRE+mvYFQWAmc5ttXc1tREd5Gc4e6WPUTndpZzuUk57\nDMuiMDY3yJhRQVo6uli3c+hvkici4lXDbkwhJvYMZ4CVN89kyugcN6OJiFhJYwpJ/O38MkIBs1/+\n8MGJDKcREfGGYVsUyopyWHZ1BQCvD2JR8Eofo3K6SzndpZz2GLZFAeCysgKCfh/bGlto6ejKdBwR\nEesN2zGFmC+veZ9tja18d8GFfGRyoUvJRETspDGFFP6kJB+Ad+pPZziJiIj9hn1RmFVirlnYeOAU\nkUG4ZsErfYzK6S7ldJdy2mPYF4VLS/MpyA6w42gr31i7m4ZTetaCiEgyw35MAWBD3Qn+9/q9dEai\nlBZk8a83Xkx+dqpHSYiIeI/GFNJweXkRKz87k4oxORw+1cHrdbpuQUSkNyOiKACUFmTzp+VFABw+\n6V4Xklf6GJXTXcrpLuW0x4gpCgATC83zFur1DGcRkV6NiDGFmM2HTnHfi7u4pCSPH/7FdNfeV0TE\nFkMxprAA89zlncB9Sdo84qzfCsyJW/4TzKM5Ex+3ORZ4BdgBrANGpx/5/JUWmMd11usMJBGRXqUq\nCgHgUUxhmAXcCsxMaLMQmIZ5lvPdwPK4dT91tk20DFMUpgO/ceYH3YS8LPw+ONoapqMz4sp7eqWP\nUTndpZzuUk57pCoK8zDPXt4HhIHVwKKENjcAq5zpDZi/+ic6878HjvXyvvHbrAJu7E/o8xXw+yjJ\nN0cL/2vt7kF/AI+IiNekKgplwP64+QPOsv62SVSC6VbC+VmSor1rvjDX1Kuth0+zrbF1wO9XVVU1\n4PcYCsrpLuV0l3LaI9UVXOn+KZ04qNGfP8GjfbVfsmQJ5eXlABQVFVFZWdn9HyZ2KNef+VHAzZVT\neaa2kZXPreWmS4oH9H6a17zmNZ/J+dh0XV0dANXV1QxEqhHq+cAD9IwL3A9EgIfi2jwGvIbpWgIz\nKH0VPUcCFcALQGXcNtuBq4F6oBR4FZiR+OFun30Us+toK0uef5+inCBP3XYJQf/5n4RVU1Pjib8e\nlNNdyuku5XTPYJ99tBEzgFwBZAG3AGsS2qwBFjvT84Hj9BSEZNYAdzjTdwDPpxfXHReOG8WUomxO\nnOlk08GTQ/nRIiJWS6eaXAf8GHMm0krge8A9zroVzs/YGUotwJ3AJmf5U5ijhnFAI/AtzBlJY4Ff\nAuWYQezPYYrJWQbrSAHgyc31rHrrMBeNH8WXq8qZPj53UD5HRGQoDfRIYURdvBavuTXM3z3/Pk2t\nYQC+MGciiy8rHZTPEhEZKroh3nkamxviB5+eRlWFuW7u55vrebeh/w/i8cp5y8rpLuV0l3LaY8QW\nBYCyohy+de1UbpldDMAv327UtQsiMqKN2O6jeI2nO1j89LtEorBg+ji+emX5oH+miMhgUPeRC4rz\ns/ifVeX4gJd3NLGtsSXTkUREMkJFwbHg4nH85YfNhdVPbq5Pezuv9DEqp7uU013KaQ8VhTifqSwm\nFPDx5v6T/OGDc86QFREZ9jSmkODh333A2h3NAHzlz8q57uJxQ/r5IiIDoTEFl90+t5TZE/MBWPHG\nAY451zGIiIwEKgoJivOz+OdPT+MjkwtoDUf41XtH+mzvlT5G5XSXcrpLOe2hotALn8/H5y81t9j+\n1XtHWbejiZNnOjOcSkRk8GlMIYloNMq3X9nDG3XmhnnZAR/fuGYql5cXZSSPiEg6NKYwSHw+H9/4\nxFRu+XAJFWNyaO+K8ugfDtAZ0RXPIjJ8qSj0ISvo566PTuLfbppBcX6IhtMdfPonW1i3o6m7jVf6\nGJXTXcrpLuW0h4pCGoJ+H9UfLaMgO0AU+MHv6tjT1JbpWCIirtOYQj9Eo1F+9Pv9vOwcKdxcWczN\nlcWMzQ1lOJmIiKExhSHk8/n4/JyJhAJmfz9T28g31+3WOIOIDBvpFIUFmGcq7wTuS9LmEWf9VmBO\nGts+ABwANjuvBXhESUEWy2+cwbKrP0RRTpC3NrzOmhTXMtjAK32hyuku5XSXV3IORKqiEKDnUZuz\ngFuBmQltFgLTMM9yvhtYnsa2UeCHmAIyB3h5IL/EUCsfk8Mnpo3lq39mbrH9/zYe1p1VRWRYSFUU\n5gG7MM9RDgOrgUUJbW4AVjnTG4DRwMQ0trV6PCMd88sLmTf/Y5zpjPD3/7mTfcfsHXyuqqrKdIS0\nKKe7lNNdXsk5EKmKQhmwP27+gLMsnTaTUmz7RUx300pMIfEcn8/Hdz51AXMmFdAZifLgqx9w+GR7\npmOJiJy3YIr16Y6g9vev/uXAd5zpfwIeBu7qreGSJUsoLzfdNEVFRVRWVnZX61j/Xibna2tr+fqd\nf8Pdz25jyx9f5653NrL6H/+SwpygFfli8/F9oTbk6Wt/3nvvvdbk0f7U/rR9f8am6+rqAKiurmYg\nUn2Zz8cMCscGgu8HIsBDcW0eA17DdA+BGVi+CpiaxrYAFcALQGXih9t2SmpvampqqKqqork1zNdf\n3s2e5jZyQ34+c0kxV184hvLROZmOCPTktJ1yuks53eWFnAM9JTXVhkHgfeAa4BDwJmbAeFtcm4XA\nUufnfODHzs++ti0FDjvbfwX4KHBb4od7oSjEO3Synf/zX3vZedSMLQT9Ph687kJmlxZkOJmIjBQD\nLQqpuo86MV/4azFnE63EfKnf46xfAbyIKQi7gBbgzhTbgjlauBTTPbU37v08bVJhNv964ww2HTzJ\nTzce5v0jrXzt17v48+lj+fsrP5TpeCIiKaVzncJLwMWY006/5yxb4bxiljrrPwxsSrEtwGJgttP+\nRqDhPLJbobfzlueWFfKDT19EpfOwnrU7mnnp/aaMDkJ75fxq5XSXcrrLKzkHItWRgpyn7KCfh6+/\niH/fcJBnahv50e/NINDkomzmTCrgjstKKczR7hcRu1h9rYDXxhR6c6Yzws/eOkxt/Wnqjp+hLRwB\nICfo5575ZXx6xvgMJxSR4WSwxxRkgHKCfu6+3Fye0RbuYseRVp5+u4GNB07xLzX7ebf+NNMn5PHx\nC8dQpCMHEckw3RBvgPrTxzgqFODDkwr47oJp/O38MnzA+l3H+LfXD3DbU+/wnfV7+PcNB1m7o4nX\nPzjBjiOtdHRGhjxnJimnu5TTXV7JORD60zRDPnNJMXMmFfBG3QneqW9h44GT1Ow7cU67opwgn7lk\nArOK8xibG2JcbojcrEAGEovISKAxBUs0nOrgrYMnaW7rZP/xM7R0dHHoZDsHTpx7xtKokJ8ZE3KZ\nMjqHz1aWUFKQlYHEImIjjSkMEyUFWSxMGHSORqNsOniKdTubOXK6g+a2ME0tYdrCETYfOs3mQ6d5\ncXsTxfkhCrKD5AT95GcFuPKC0Vx9wRh8PqtrvohYSEVhgAbzsnefz8dlkwu5bHJh97JoNMrxtk5q\n60+zbmczb+4/yaGTHUBHd5v//uAE2xtb+ezsYkaPChH0+zxxeT544zYCoJxuU057qCh4jM/nY0xu\niCsvGMOVF4yhLdzFkZYwLR1dnOmMsOtoKyv/eIjn3j3Cc++ah/9MLMhiTFMDlB1nTlkBeRqTEJEk\nrO5fGEljCm7adPAkv9jcwAfHz3CqvZP4p4X6fTAhL4txuSHG5ZmB6/G5IT40JodZJXkUZOvvBBEv\n05iCnGMm6yhaAAAI8UlEQVRuWSFzy0yXU2ckyt7mNjYeOMmb+0+yvbGFhtMdNJzuOGc7vw/mlhVQ\nWpBNfnaAiyfk8tHJhYQCOnNZZKRQURgg2/sYg34fF43PpWH7Jm79iyo6OiMcbQ3T1GoGrY+2hjnS\n0sHOI61sa2xh44FTwKnu7fOyAkwqzGJuWSETC7L40Ogcpo/PJSs4OIXC9v0Zo5zuUk57qCiMMFlB\nP5MKs5lUmH3OuqaWMFsOn+JUexfH2sK8/sEJ9h07w86jbd23AwcI+GBiQTZ/UpJHWVE2F43PZUJe\niAl5WbqGQsTjNKYgSUWjUY62htnb3Ma2xlaOnO5gx9FWPjh2Jukj+XJDfibkZzE6J0heVoDC7CCT\ni7LJCfnJDvrJCvjJDvrICvjJywowelSQMaNC5AzSkYfISKMxBRk0Pp+PCXlZTMjLYt6Uou7l7Z0R\n9jS3sbupjT1Nbew/cYajLaYbqjUc4YNjZ/ign5+VG/IzIS+L0aOChAI+QgE/WX4foaCfkN9HVsAU\nktLCbKaOyWFcnrk2I+j3EfT7CPit/vtGxDPSKQoLME9TCwCPc+7jNAEeAa4DWoG/Ajan2HYs8DTw\nIWAf8Dng+Hnkzziv9DG6mTM76GdmcR4zi/POWh6NRjnV3sWRlg5OtnfR0t5FU2uYQ6faCXdGae+K\n0NEZob0rQntnlJYO0011vK3TFJPjZ6h9awuFF17a70xjc4OMz80iLytAfnaAvJDzM8u88rN6pvOy\n/ORnBcnPDjAq5Md/Hhf5jcT/7oNJOe2RqigEgEeBa4GDwB+BNZz7OM5pwEXA5cByzOM4+9p2GfAK\n8H3gPmd+mRu/0FCrra31xD+Socjp8/kozAn2+zkR8cXkJ//xGov+/AI6uqKEu6KEuyLOdIQznRH2\nHz9D3fF2mlvDtIa76IyYds2tnTS3dvY/M5CbFSDX6d7KDvrJDsSmzdFJwDkaCfp9BHzmqOSN/6xh\nz6gLyQ35u4tNrvNzVMh0k4UCPrIDfkaF/Bk7g0v/Pt3llZwDker/3nmYx2zuc+ZXA4s4uyjcAKxy\npjcAo4GJwNQ+tr0BuMpZvgp4DY8WhRMnzr2JnY1szhlfTApoP6urKh1dkag5m6rVXMTX0tHFaedn\nS3sXLeEuTrd3nbuuo4vWcKR7uj8O7qmnYXN92u39PrrHVHKCfrICvu75rGBPwYnvDov9DHQXI7qL\nUuwVctqFAs50wEfQb7rcQgEf2/c38vbhU2ZZoKdtwH/2Z571eT6G/BYpNv/7jOeVnAORqiiUAfvj\n5g9gjgZStSkDJvWxbQk9j+BscOZFzkvA76M4P4vi/P7fGLArEqU13EVrR6xbyxyRtHdG6OiK0NEZ\npTMSpSvq/IyYn8+9W8An50ykJdxFa0cXLR0Rp8iYAhM7gmnvjNAa7iIShbZwhLZwhKH8Wjm46xjb\nfr2r39sFfJxVlIJxxencwkWvR1Nnbe+Ln+fs7X0+3m1o4dnaxrO2yQr4KC3IJhiwZ7yoqTXMjqOt\nSddfOHaU58e3UhWFZCeZJEpnL/iSvF+0H59jnbq6ukxHSIty9i7g91GQHaTg3DN0+7S+vYnFl5Wm\n1TbqFJQOp0j0jK1E6XCKjyk45mLD+OLTFTXTXZEoXVGIRM4tUuFIlM6uqFOIIoSdgtQVibLuTBOV\nE/MJO58Rv66z+32jZ31uJApdUejqciaGwJ53dtKw4eCQfNZA7Hn9XbaWv590/XOLZ3v+NjKpvszn\nAw9gBowB7gcinD3Y/Bim+2e1M78d0zU0tY9ttwNXA/VAKfAqMCPxw5944oldpaWlF6b924iIjHCH\nDx/effvtt08brPcPAruBCiAL2ALMTGizEHjRmZ4PvJHGtrEBZjBjCQ+6nlxERAbFdcD7mEHj+51l\n9zivmEed9VuBuSm2BXNK6npgB7AOMzgtIiIiIiLStwWYcYed9HQz2WIf8DbmAr03nWVjMdddZPLI\n5yeYM7lq45b1let+zP7dDnxqiDJC7zkfwJydttl5XRe3LhM5p2DGud4F3gG+5Cy3bX8my/kAdu3P\nHMzp6luA94DvOctt25/Jcj6AXfsTzHVgm4EXnHnb9qWrApjupgogRO/jGJm0F/MfIN73gX90pu8j\nM2MkfwbM4ewv22S5ZmH2awizn3cBQ3V1VW85vw18tZe2mco5EYhdVp2P6QKdiX37M1lO2/YnQK7z\nM4gZd6zCvv2ZLKeN+/OrwJOYC4LBxX1p413I4i+YC9Nz0ZtNEs/air+AbxVw49DGAeD3wLGEZcly\nLQKewuzffZj9PW/wIwK954Tez4TLVM56zP9IAKcxF1yWYd/+TJYT7NqfYG6BA+akkwDm34Bt+zNZ\nTrBrf07GnODzeFwu1/aljUUh2cVwtohiBsk3An/jLLP1YrxkuSZh9muMDfv4i5gTFVbSc+hrQ84K\nzJHNBuzenxWYnLGz/2zbn35MAWugp8vLxv3ZW06wa3/+CPgHzCn+Ma7tSxuLgu0Xsl2B+Z/vOuDv\nMN0h8Wy9GC9VrkxmXo65ruVS4DDwcB9thzJnPvAs8GXinzzUk8OW/ZkPPIPJeRo792cEk2cycCXw\n8V5y2LA/E3NejV3783qgETOekOw6swHtSxuLwkHMAFrMFM6udJl22Pl5BHgOcyjWgOnfBXMxXmMG\ncvUmWa7EfTzZWZYpjfT8Q36cnsPbTOYMYQrCE8DzzjIb92cs58/pyWnj/ow5AfwauAw792dMLOdH\nsGt/fgzTVbQX0y30Ccy/UZv35YClc8FcpuQCBc50HvDfmNF8Wy7Gq+DcgebecsUGn7IwfwHtZmgf\nuFTB2Tnj7xfxFeAXznSmcvqAn2EO0+PZtj+T5bRtf46np8tlFPA74Brs25/Jck6Ma2PD/oy5ip6z\nj2zbl65LdtFbpk3F7OAtmFMAY9lsuBjvKeAQ0IEZk7kzRa6vY/bvduDPM5jzrzFfbG9j+myf5+wx\nmUzkrMJ0I2yh5zTEBdi3P3vLeR327c9KYJOT821MfzjYtz+T5bRtf8ZcRc/ZR7btSxERERERERER\nERERERERERERERERERERERERkR7/H6G8/kXhRzmiAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1126c9150>"
       ]
      }
     ],
     "prompt_number": 1125
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "hyperopt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will use [Gradient Boosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) which usually gives better results than L1 or RF. In addition, like RF, it does not require normalization or PCA. However, unlike RF or L1 it has many hyper parameters that can effect its performance. In addition we need to decide how many features we want to use which is another hyper-parameter. Instead of manually guessing, we can use the [hyperopt](http://hyperopt.github.io/hyperopt/) to do the guesing for us"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we will perform several hyperopt search in parallel each running on a different bootstrap sample of the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "shared memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data itself is identical so there is no need to duplicate it for each process and we will use shared memory (shmem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/X.mmap\n",
      "mmX = np.memmap('/tmp/X.mmap', shape=X.shape, dtype=np.float32, mode='w+')\n",
      "mmX[:,:] = X\n",
      "del mmX # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1126
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use ipython parallel processing infrastructure. Visit [Clusters tab in the Home page of ipython](../tree#clusters) and start 8 engines (or as many cores you have on your machine) from the default profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR you can run the command line:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "ipcluster start --n=8\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait a little bit (otherwise you will get an error on next cell)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!sleep 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "#lv.set_flags(block = False, retries = 0)\n",
      "clients=client[:]\n",
      "Ncores = len(clients)\n",
      "Ncores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1128,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 1128
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "copy some information to all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['X_shape'] = X.shape\n",
      "clients['y'] = y\n",
      "clients['psegments'] = psegments\n",
      "clients['nsegments'] = nsegments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load the shared memory on all engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "N, NF = X_shape\n",
      "X = np.memmap('/tmp/X.mmap', shape=X_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import random, itertools\n",
      "def random_train_validation_split(psegments=psegments, nsegments=nsegments, N=N):\n",
      "    \"\"\"Randomly pick one positive segment for validation and a matching number of negative segments\"\"\"\n",
      "    Nps = len(psegments)\n",
      "    assert Nps > 1\n",
      "    Nns = len(nsegments)\n",
      "    assert Nns > 1\n",
      "    npsratio = float(Nns)/Nps\n",
      "    Ntrainps = 1\n",
      "    Ntrainns = min(max(1,int(Ntrainps*npsratio+0.5)), Nns-1) # make sure we have something to train\n",
      "    \n",
      "    s = random.choice(psegments)\n",
      "    ns = random.sample(nsegments,Ntrainns) # sequence based\n",
      "    n = np.array(list(itertools.chain(*ns))) # .ravel does not work - elements of nsegments are not of equal length\n",
      "    sample_validate = np.concatenate((s, n))\n",
      "\n",
      "    return np.setdiff1d(xrange(N),sample_validate,True), sample_validate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1131
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will optimize AUC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "myscore = roc_auc_score\n",
      "clients['myscore'] = myscore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "def hyperopt_work(args):\n",
      "    from lockfile import LockFile\n",
      "    \n",
      "    sample_train, sample_validate = random_train_validation_split()    \n",
      "\n",
      "    X_trn = X[sample_train,:]\n",
      "    y_trn = y[sample_train]\n",
      "    \n",
      "    X_val = X[sample_validate,:]\n",
      "    y_val = y[sample_validate]\n",
      "        \n",
      "    def t_est(params):\n",
      "        try:\n",
      "            args = {}\n",
      "            for h, p in params.iteritems():\n",
      "                if h.startswith('I'):\n",
      "                    args[h[1:]] = int(p)\n",
      "                else:\n",
      "                    args[h] = p\n",
      "            \n",
      "            from sklearn.ensemble import GradientBoostingClassifier \n",
      "            est = GradientBoostingClassifier()\n",
      "            est.set_params(**dict((k,v) for k,v in args.iteritems() if k not in ['nf']))\n",
      "\n",
      "            nf = args['nf']\n",
      "            est.fit(X_trn[:,:nf], y_trn)\n",
      "            \n",
      "            y_train = est.predict_proba(X_trn[:,:nf])\n",
      "            y_validate = est.predict_proba(X_val[:,:nf])\n",
      "            #from sklearn.metrics import average_precision_score\n",
      "            train_score = myscore(y_trn, y_train[:,1])\n",
      "            validate_score = myscore(y_val, y_validate[:,1])\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('/tmp/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, validate_score, train_score, args\n",
      "            from hyperopt import STATUS_OK\n",
      "            return {'loss':1.-validate_score, 'status':STATUS_OK, 'train_score':train_score, 'validate_score':validate_score}\n",
      "        except:\n",
      "            lock = LockFile('.lock')\n",
      "            with lock:\n",
      "                with open('/tmp/hyperopt.txt','a') as fp:\n",
      "                    print >>fp, 'failed', args\n",
      "            from hyperopt import STATUS_FAIL\n",
      "            return {'status':STATUS_FAIL, 'loss':1.} # 'loss' is mandatory\n",
      "            \n",
      "    \n",
      "    max_evals = args.get('max_evals', 10)\n",
      "    from hyperopt import fmin, tpe, Trials\n",
      "    space = args.get('space')\n",
      "    trials = Trials()\n",
      "    best = fmin( t_est, space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
      "    import cPickle as pickle\n",
      "    lock = LockFile('.lock')\n",
      "    with lock:\n",
      "        with open('/tmp/hyperopt.spkl','ab') as fp:\n",
      "                pickle.dump(trials, fp, -1)\n",
      "    return best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define statistical space in which we will do our hper-parameter search. An \"I\" at the start indicates that the value is an int"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from hyperopt import hp\n",
      "from math import log\n",
      "space = {\n",
      "    'n_estimators': 100,\n",
      "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.)),\n",
      "    'Inf': hp.quniform( 'nf', 10, NF, 1),\n",
      "    'Imax_features': hp.quniform( 'max_features', 10, 30, 1),\n",
      "    'Imax_depth': hp.quniform( 'max_depth', 2, 18, 1),\n",
      "    'Imin_samples_leaf': hp.quniform( 'min_samples_leaf', 2, 30, 1),\n",
      "    'subsample': hp.uniform( 'subsample', 0.2, 0.9),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/hyperopt.*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1135
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "run hyperopt searches in parallel on all cores.\n",
      "Each hyperopt search will do 100 evaluations of the hyper parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "hyperopt_work({'space':space, 'max_evals':100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:86]: \u001b[0m\n",
        "{'learning_rate': 0.3776487170395898,\n",
        " 'max_depth': 4.0,\n",
        " 'max_features': 13.0,\n",
        " 'min_samples_leaf': 20.0,\n",
        " 'nf': 30.0,\n",
        " 'subsample': 0.554708208049699}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:86]: \u001b[0m\n",
        "{'learning_rate': 0.9771662443798854,\n",
        " 'max_depth': 8.0,\n",
        " 'max_features': 16.0,\n",
        " 'min_samples_leaf': 15.0,\n",
        " 'nf': 222.0,\n",
        " 'subsample': 0.378402675269761}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:86]: \u001b[0m\n",
        "{'learning_rate': 0.9752453438911473,\n",
        " 'max_depth': 3.0,\n",
        " 'max_features': 12.0,\n",
        " 'min_samples_leaf': 11.0,\n",
        " 'nf': 130.0,\n",
        " 'subsample': 0.29878655295099393}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:86]: \u001b[0m\n",
        "{'learning_rate': 0.017915074377297953,\n",
        " 'max_depth': 13.0,\n",
        " 'max_features': 23.0,\n",
        " 'min_samples_leaf': 13.0,\n",
        " 'nf': 342.0,\n",
        " 'subsample': 0.6551075238302243}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:86]: \u001b[0m\n",
        "{'learning_rate': 0.2468688255539961,\n",
        " 'max_depth': 8.0,\n",
        " 'max_features': 24.0,\n",
        " 'min_samples_leaf': 7.0,\n",
        " 'nf': 24.0,\n",
        " 'subsample': 0.43475958915631335}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:86]: \u001b[0m\n",
        "{'learning_rate': 0.02213893070651073,\n",
        " 'max_depth': 14.0,\n",
        " 'max_features': 30.0,\n",
        " 'min_samples_leaf': 26.0,\n",
        " 'nf': 36.0,\n",
        " 'subsample': 0.6282720530604495}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:86]: \u001b[0m\n",
        "{'learning_rate': 0.6954336157736449,\n",
        " 'max_depth': 10.0,\n",
        " 'max_features': 13.0,\n",
        " 'min_samples_leaf': 18.0,\n",
        " 'nf': 119.0,\n",
        " 'subsample': 0.2991411883537185}"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:86]: \u001b[0m\n",
        "{'learning_rate': 0.32862597665107274,\n",
        " 'max_depth': 17.0,\n",
        " 'max_features': 10.0,\n",
        " 'min_samples_leaf': 11.0,\n",
        " 'nf': 12.0,\n",
        " 'subsample': 0.819244333001978}"
       ]
      }
     ],
     "prompt_number": 1136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wait for the jobs to end. This will take some time. Also your computer can get really hot, so use the time to arange some cooling to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -n -r /tmp/hyperopt.txt > /tmp/hyperopt.sort.txt\n",
      "!head -n 5 /tmp/hyperopt.sort.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0 1.0 {'learning_rate': 0.6954336157736449, 'nf': 119, 'min_samples_leaf': 18, 'n_estimators': 100, 'subsample': 0.2991411883537185, 'max_features': 13, 'max_depth': 10}\r\n",
        "1.0 1.0 {'learning_rate': 0.6436645493045031, 'nf': 276, 'min_samples_leaf': 2, 'n_estimators': 100, 'subsample': 0.664469259976527, 'max_features': 17, 'max_depth': 12}\r\n",
        "1.0 1.0 {'learning_rate': 0.557927469852681, 'nf': 280, 'min_samples_leaf': 16, 'n_estimators': 100, 'subsample': 0.8807842311232078, 'max_features': 18, 'max_depth': 13}\r\n",
        "1.0 1.0 {'learning_rate': 0.4047384963549155, 'nf': 323, 'min_samples_leaf': 13, 'n_estimators': 100, 'subsample': 0.801579376128751, 'max_features': 20, 'max_depth': 14}\r\n",
        "1.0 1.0 {'learning_rate': 0.32926089154341304, 'nf': 245, 'min_samples_leaf': 21, 'n_estimators': 100, 'subsample': 0.7693070531986483, 'max_features': 18, 'max_depth': 9}\r\n"
       ]
      }
     ],
     "prompt_number": 1137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('/tmp/hyperopt.sort.txt')\n",
      "hyeropt_results = []\n",
      "for l in fp:\n",
      "    if l.startswith('failed'):\n",
      "        continue\n",
      "    l = l.split()\n",
      "    validate_score = l[0]\n",
      "    train_score = l[1]\n",
      "    args = eval(''.join(l[2:]))\n",
      "    hyeropt_results.append((validate_score, train_score, args))\n",
      "fp.close()\n",
      "len(hyeropt_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1138,
       "text": [
        "769"
       ]
      }
     ],
     "prompt_number": 1138
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicition/Bagging/Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdata = read_data(target, 'test', FEATURES)\n",
      "Nt, NFF = tdata.X.shape\n",
      "Nt, NFF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1139,
       "text": [
        "(150, 360)"
       ]
      }
     ],
     "prompt_number": 1139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/Xt.mmap\n",
      "Xt_shape = (tdata.X.shape[0], NF)\n",
      "mmXt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='w+')\n",
      "mmXt[:,:] = tdata.X\n",
      "del mmXt # flush to disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clients['Xt_shape'] = Xt_shape\n",
      "clients['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "Xt = np.memmap('/tmp/Xt.mmap', shape=Xt_shape, dtype=np.float32, mode='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_work(args):\n",
      "    from lockfile import LockFile\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    import cPickle as pickle\n",
      "\n",
      "    N = X_shape[0]\n",
      "    NF = int(args.get('nf', X_shape[1]))\n",
      "#     while True:\n",
      "    # use out-of-bag samples to estimate the generalization error\n",
      "    sample_train, sample_validate = random_train_validation_split()    \n",
      "\n",
      "    X_trn = X[sample_train,:NF]\n",
      "    y_trn = y[sample_train]\n",
      "#         if np.any(y_trn == 1) and np.any(y_trn == 0):\n",
      "#             break\n",
      "    \n",
      "    X_val = X[sample_validate,:NF]\n",
      "    y_val = y[sample_validate]\n",
      "    \n",
      "    X_test = Xt[:,:NF]\n",
      "    \n",
      "\n",
      "    from sklearn.ensemble import GradientBoostingClassifier \n",
      "    est = GradientBoostingClassifier(n_estimators=1000)\n",
      "\n",
      "    est.set_params(**dict((k,v) for k, v in args.iteritems() if k not in  ['nf']))\n",
      "    try:\n",
      "        est.fit(X_trn, y_trn)\n",
      "\n",
      "        y_val_est = est.predict_proba(X_val)[:,1]\n",
      "        \n",
      "        y_test_est = est.predict_proba(X_test)[:,1]\n",
      "\n",
      "        lock = LockFile('.lock')\n",
      "        with lock:\n",
      "            with open('/tmp/predict.spkl','ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump((sample_validate,y_val_est), fp, -1)\n",
      "            with open('/tmp/%s_test.spkl'%target,'ab') as fp:\n",
      "                # in a later stage we will use the OOB samples to make predictions on all samples\n",
      "                # so keep a record of the index of each OOB sample\n",
      "                pickle.dump(y_test_est, fp, -1)\n",
      "    except Exception as e:\n",
      "        return e\n",
      "    #  (their p_ratio will be different) so this error measure is not completely accurate\n",
      "    return myscore(y_val, y_val_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm /tmp/predict.spkl\n",
      "!rm /tmp/{target}_test.spkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "args_list = []\n",
      "for res in hyeropt_results:\n",
      "    params = res[2]\n",
      "    args = {}\n",
      "    for k,v in params.iteritems():\n",
      "        if k.startswith('I'):\n",
      "            args[k[1:]] = int(v)\n",
      "        else:\n",
      "            args[k] = v\n",
      "    print args\n",
      "    args_list.append(args)\n",
      "    if len(args_list) >= 16:\n",
      "        break\n",
      "len(args_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'learning_rate': 0.6954336157736449, 'nf': 119, 'min_samples_leaf': 18, 'n_estimators': 100, 'subsample': 0.2991411883537185, 'max_features': 13, 'max_depth': 10}\n",
        "{'learning_rate': 0.6436645493045031, 'nf': 276, 'min_samples_leaf': 2, 'n_estimators': 100, 'subsample': 0.664469259976527, 'max_features': 17, 'max_depth': 12}\n",
        "{'learning_rate': 0.557927469852681, 'nf': 280, 'min_samples_leaf': 16, 'n_estimators': 100, 'subsample': 0.8807842311232078, 'max_features': 18, 'max_depth': 13}\n",
        "{'learning_rate': 0.4047384963549155, 'nf': 323, 'min_samples_leaf': 13, 'n_estimators': 100, 'subsample': 0.801579376128751, 'max_features': 20, 'max_depth': 14}\n",
        "{'learning_rate': 0.32926089154341304, 'nf': 245, 'min_samples_leaf': 21, 'n_estimators': 100, 'subsample': 0.7693070531986483, 'max_features': 18, 'max_depth': 9}\n",
        "{'learning_rate': 0.32862597665107274, 'nf': 12, 'min_samples_leaf': 11, 'n_estimators': 100, 'subsample': 0.819244333001978, 'max_features': 10, 'max_depth': 17}\n",
        "{'learning_rate': 0.053910663649558564, 'nf': 328, 'min_samples_leaf': 6, 'n_estimators': 100, 'subsample': 0.8852987234994361, 'max_features': 29, 'max_depth': 8}\n",
        "{'learning_rate': 0.05121308375040772, 'nf': 62, 'min_samples_leaf': 8, 'n_estimators': 100, 'subsample': 0.3072511558298576, 'max_features': 13, 'max_depth': 6}\n",
        "{'learning_rate': 0.04738496658779072, 'nf': 346, 'min_samples_leaf': 11, 'n_estimators': 100, 'subsample': 0.5337115479767695, 'max_features': 22, 'max_depth': 11}\n",
        "{'learning_rate': 0.039461851736245813, 'nf': 243, 'min_samples_leaf': 13, 'n_estimators': 100, 'subsample': 0.4971995716722942, 'max_features': 24, 'max_depth': 13}\n",
        "{'learning_rate': 0.03827664988234879, 'nf': 327, 'min_samples_leaf': 7, 'n_estimators': 100, 'subsample': 0.44192265197991215, 'max_features': 22, 'max_depth': 13}\n",
        "{'learning_rate': 0.022921685113512422, 'nf': 279, 'min_samples_leaf': 21, 'n_estimators': 100, 'subsample': 0.8986340658016608, 'max_features': 27, 'max_depth': 8}\n",
        "{'learning_rate': 0.020364407218280783, 'nf': 193, 'min_samples_leaf': 3, 'n_estimators': 100, 'subsample': 0.8421698387661543, 'max_features': 18, 'max_depth': 13}\n",
        "{'learning_rate': 0.02022685875623956, 'nf': 221, 'min_samples_leaf': 3, 'n_estimators': 100, 'subsample': 0.8467180724409856, 'max_features': 17, 'max_depth': 15}\n",
        "{'learning_rate': 0.018539755390494062, 'nf': 348, 'min_samples_leaf': 17, 'n_estimators': 100, 'subsample': 0.612558310999018, 'max_features': 24, 'max_depth': 12}\n",
        "{'learning_rate': 0.017968363096478666, 'nf': 205, 'min_samples_leaf': 20, 'n_estimators': 100, 'subsample': 0.8314430673687558, 'max_features': 27, 'max_depth': 5}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1145,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 1145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(predict_work, args_list*Ncores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "itr = results.__iter__()\n",
      "while True:\n",
      "    try:\n",
      "        r = itr.next()\n",
      "    except StopIteration:\n",
      "        print 'stopped'\n",
      "        break\n",
      "    except IPython.parallel.error.RemoteError as e:\n",
      "        print e\n",
      "        continue\n",
      "    except Exception as e:\n",
      "        print e.__class__\n",
      "        continue\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.672101449275\n",
        "0.358695652174\n",
        "0.0398550724638\n",
        "0.847826086957\n",
        "0.0634057971014\n",
        "0.932971014493\n",
        "0.929347826087\n",
        "0.731884057971\n",
        "0.731884057971\n",
        "0.579710144928\n",
        "0.507246376812\n",
        "0.463768115942\n",
        "0.33152173913\n",
        "0.753623188406\n",
        "0.166666666667\n",
        "0.222826086957\n",
        "0.742753623188\n",
        "0.664855072464\n",
        "0.634057971014\n",
        "0.378623188406\n",
        "0.313405797101\n",
        "0.519927536232\n",
        "0.231884057971\n",
        "0.572463768116\n",
        "0.217391304348\n",
        "0.00724637681159\n",
        "0.192028985507\n",
        "0.789855072464\n",
        "0.815217391304\n",
        "0.760869565217\n",
        "0.427536231884\n",
        "0.503623188406\n",
        "0.526268115942\n",
        "0.438405797101\n",
        "0.981884057971\n",
        "0.0\n",
        "0.0\n",
        "0.63134057971\n",
        "0.541666666667\n",
        "0.173913043478\n",
        "1.0\n",
        "0.538043478261\n",
        "0.840579710145\n",
        "0.630434782609\n",
        "0.873188405797\n",
        "0.317028985507\n",
        "0.853260869565\n",
        "0.682971014493\n",
        "1.0\n",
        "0.925724637681\n",
        "0.56884057971\n",
        "0.0380434782609\n",
        "0.166666666667\n",
        "0.797101449275\n",
        "0.813405797101\n",
        "0.590579710145\n",
        "0.41847826087\n",
        "0.733695652174\n",
        "0.489130434783\n",
        "0.559782608696\n",
        "0.0\n",
        "0.271739130435\n",
        "0.724637681159\n",
        "0.985507246377\n",
        "0.5\n",
        "0.586956521739\n",
        "0.106884057971\n",
        "0.0018115942029\n",
        "0.592391304348\n",
        "0.789855072464\n",
        "0.655797101449\n",
        "0.661231884058\n",
        "0.534420289855\n",
        "0.297101449275\n",
        "0.630434782609\n",
        "0.721014492754\n",
        "0.545289855072\n",
        "0.623188405797\n",
        "0.239130434783\n",
        "0.38768115942\n",
        "0.675724637681\n",
        "0.0416666666667\n",
        "0.659420289855\n",
        "0.432971014493\n",
        "0.842391304348\n",
        "0.789855072464\n",
        "0.16847826087\n",
        "0.0\n",
        "0.403985507246\n",
        "0.538043478261\n",
        "0.644927536232\n",
        "0.135869565217\n",
        "0.715579710145\n",
        "0.213768115942\n",
        "0.509057971014\n",
        "0.885869565217\n",
        "0.583333333333\n",
        "0.903985507246\n",
        "0.744565217391\n",
        "0.563405797101\n",
        "0.0\n",
        "0.0815217391304\n",
        "0.521739130435\n",
        "0.88768115942\n",
        "0.00905797101449\n",
        "0.952898550725\n",
        "0.865942028986\n",
        "0.266304347826\n",
        "0.554347826087\n",
        "0.998188405797\n",
        "0.972826086957\n",
        "0.0036231884058\n",
        "0.0018115942029\n",
        "0.757246376812\n",
        "0.182971014493\n",
        "0.0\n",
        "0.836956521739\n",
        "0.958333333333\n",
        "0.0742753623188\n",
        "0.951086956522\n",
        "0.961956521739\n",
        "0.0018115942029\n",
        "0.70652173913\n",
        "0.891304347826\n",
        "0.166666666667\n",
        "0.675724637681\n",
        "0.809782608696\n",
        "0.172101449275\n",
        "stopped\n"
       ]
      }
     ],
     "prompt_number": 1147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = open('/tmp/predict.spkl','rb')\n",
      "count = 0\n",
      "y_est = np.zeros(N)\n",
      "y_count = np.zeros(N)\n",
      "vals = []\n",
      "while True:\n",
      "    try:\n",
      "        sample_validate,y_val_est = pickle.load(fp)\n",
      "    except:\n",
      "        break\n",
      "    count += 1\n",
      "    y_est[sample_validate] += y_val_est\n",
      "    y_count[sample_validate] += 1\n",
      "\n",
      "    idx = y_val_est.argsort()[::-1]\n",
      "    n = len(y_val_est)\n",
      "    val_recall_support = np.zeros(n)\n",
      "    p_sum = 0.\n",
      "    for i,j in enumerate(idx):\n",
      "        p_sum += float(y[sample_validate[j]])\n",
      "        val_recall_support[i] = p_sum\n",
      "    val_x = np.linspace(0.,100.,n)\n",
      "    vals.append((val_x, val_recall_support))\n",
      "\n",
      "y_est /= y_count\n",
      "y_est[y_count == 0] = y.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_no_overlap = [r for r,l in zip(y, latencies) if abs(l-int(l)) < 0.01]\n",
      "y_est_no_overlap = [r for r,l in zip(y_est, latencies) if abs(l-int(l)) < 0.01]\n",
      "myscore(y_no_overlap, y_est_no_overlap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1149,
       "text": [
        "0.44576719576719581"
       ]
      }
     ],
     "prompt_number": 1149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/tmp/%s_predict.spkl'%target,'wb') as fp:\n",
      "    pickle.dump((y_no_overlap, y_est_no_overlap), fp, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "after running the entire notebook, again and again, on all targets - continue to 140926-GBC-combine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1150
    }
   ],
   "metadata": {}
  }
 ]
}